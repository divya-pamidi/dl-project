{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:10:54.601906Z","iopub.status.busy":"2023-12-10T20:10:54.600984Z","iopub.status.idle":"2023-12-10T20:10:54.609005Z","shell.execute_reply":"2023-12-10T20:10:54.607958Z","shell.execute_reply.started":"2023-12-10T20:10:54.601871Z"},"trusted":true},"outputs":[],"source":["import unicodedata\n","import re\n","from tqdm import tqdm\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s\n","\n","\n","def load_lines(path):\n","    sentences = []\n","    with open(path, encoding='utf8') as f:\n","        for line in tqdm(f):\n","            sentences.append(normalizeString(line))\n","    return sentences"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:10:56.057165Z","iopub.status.busy":"2023-12-10T20:10:56.056788Z","iopub.status.idle":"2023-12-10T20:11:03.091491Z","shell.execute_reply":"2023-12-10T20:11:03.090470Z","shell.execute_reply.started":"2023-12-10T20:10:56.057132Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["europarl-v7.de-en.de\n","europarl-v7.de-en.en\n"]}],"source":["!tar -xvzf /kaggle/input/europarl/de-en\\ \\(1\\).tgz -C /kaggle/working/"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:11:03.093645Z","iopub.status.busy":"2023-12-10T20:11:03.093327Z","iopub.status.idle":"2023-12-10T20:15:40.549193Z","shell.execute_reply":"2023-12-10T20:15:40.548233Z","shell.execute_reply.started":"2023-12-10T20:11:03.093616Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["1920209it [02:28, 12939.96it/s]\n","1920209it [02:09, 14880.87it/s]\n"]}],"source":["\n","# Loading the data\n","de_data = load_lines('/kaggle/working/europarl-v7.de-en.de')\n","en_data = load_lines('/kaggle/working/europarl-v7.de-en.en')\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:15:40.553897Z","iopub.status.busy":"2023-12-10T20:15:40.552815Z","iopub.status.idle":"2023-12-10T20:15:40.559416Z","shell.execute_reply":"2023-12-10T20:15:40.558538Z","shell.execute_reply.started":"2023-12-10T20:15:40.553856Z"},"trusted":true},"outputs":[],"source":["SOS = 0\n","EOS = 1\n","PAD = 2\n","en_word_count = [3]\n","de_word_count = [3]\n","en_word_counter = {}\n","de_word_counter = {}\n","en_word_index = {}\n","de_word_index = {}"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:15:40.561575Z","iopub.status.busy":"2023-12-10T20:15:40.561296Z","iopub.status.idle":"2023-12-10T20:15:40.572246Z","shell.execute_reply":"2023-12-10T20:15:40.571398Z","shell.execute_reply.started":"2023-12-10T20:15:40.561551Z"},"trusted":true},"outputs":[],"source":["def tokenize(sentence, word_counter, word_index, word_count, MAX_LEN=10):\n","    split_sentence = [word for word in sentence.split(' ')]\n","    tokenized = [SOS]\n","    if len(split_sentence)>MAX_LEN:\n","        return None\n","    for i in split_sentence[:MAX_LEN]:\n","        if i in word_index:\n","            word_counter[i] += 1\n","            tokenized.append(word_index[i])\n","        else:\n","            word_index[i] = word_count[0]\n","            word_count[0] += 1\n","            word_counter[i] = 1\n","            tokenized.append(word_index[i])\n","    tokenized.append(EOS)\n","    tokenized += [PAD]*(MAX_LEN - len(split_sentence))\n","    return tokenized"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:15:40.573606Z","iopub.status.busy":"2023-12-10T20:15:40.573345Z","iopub.status.idle":"2023-12-10T20:15:58.802969Z","shell.execute_reply":"2023-12-10T20:15:58.802092Z","shell.execute_reply.started":"2023-12-10T20:15:40.573582Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 1920209/1920209 [00:18<00:00, 105436.23it/s]"]},{"name":"stdout","output_type":"stream","text":["[[0, 3, 4, 5, 1, 2, 2, 2, 2, 2, 2, 2], [0, 6, 7, 8, 9, 10, 11, 12, 10, 13, 14, 1], [0, 19, 20, 21, 22, 14, 1, 2, 2, 2, 2, 2], [0, 19, 20, 21, 22, 14, 1, 2, 2, 2, 2, 2], [0, 19, 20, 23, 1, 2, 2, 2, 2, 2, 2, 2], [0, 24, 25, 26, 27, 16, 28, 6, 29, 30, 14, 1], [0, 16, 31, 4, 32, 33, 34, 35, 14, 1, 2, 2], [0, 50, 51, 52, 53, 54, 55, 1, 2, 2, 2, 2], [0, 50, 49, 45, 56, 57, 16, 58, 40, 59, 55, 1], [0, 60, 61, 62, 63, 16, 64, 14, 1, 2, 2, 2]]\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["from tqdm import tqdm\n","de_data_tokenized = []\n","en_data_tokenized = []\n","de_test_data = []\n","en_test_data = []\n","import random\n","for i in tqdm(range(len(de_data))):\n","    tokens_ret_de = tokenize(de_data[i], de_word_counter, de_word_index, de_word_count)\n","    tokens_ret_en = tokenize(en_data[i], en_word_counter, en_word_index, en_word_count)\n","    if (tokens_ret_de != None) and (tokens_ret_en != None):\n","        if random.random() < 0.05:\n","            de_test_data.append(tokens_ret_de)\n","            en_test_data.append(tokens_ret_en)\n","        else:\n","            en_data_tokenized.append(tokens_ret_en)\n","            de_data_tokenized.append(tokens_ret_de)\n","    \n","\n","\n","print(de_data_tokenized[:10])\n","en_word_count = en_word_count[0]\n","de_word_count = de_word_count[0]"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:15:58.804496Z","iopub.status.busy":"2023-12-10T20:15:58.804202Z","iopub.status.idle":"2023-12-10T20:15:58.809428Z","shell.execute_reply":"2023-12-10T20:15:58.808536Z","shell.execute_reply.started":"2023-12-10T20:15:58.804470Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["188878\n","188878\n"]}],"source":["print(len(de_data_tokenized))\n","print(len(en_data_tokenized))"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:15:58.811012Z","iopub.status.busy":"2023-12-10T20:15:58.810749Z","iopub.status.idle":"2023-12-10T20:16:02.163680Z","shell.execute_reply":"2023-12-10T20:16:02.162902Z","shell.execute_reply.started":"2023-12-10T20:15:58.810989Z"},"trusted":true},"outputs":[],"source":["import torch\n","def gen_batches(input_data, output_data, batch_size):\n","    batches = []\n","    for i in tqdm(range(0, len(input_data), batch_size)):\n","        count = min(len(input_data) - batch_size, batch_size)\n","        input_tensor = torch.LongTensor(input_data[i:i+count][:]).cuda()\n","        output_tensor = torch.LongTensor(output_data[i:i+count][:]).cuda()\n","        batches.append([input_tensor, output_tensor])\n","    return batches"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:16:02.165655Z","iopub.status.busy":"2023-12-10T20:16:02.164927Z","iopub.status.idle":"2023-12-10T20:16:05.991712Z","shell.execute_reply":"2023-12-10T20:16:05.990772Z","shell.execute_reply.started":"2023-12-10T20:16:02.165616Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [00:03<00:00, 784.43it/s] \n","100%|██████████| 156/156 [00:00<00:00, 2982.60it/s]\n"]}],"source":["data_loader = gen_batches(en_data_tokenized, de_data_tokenized, 64)\n","test_data_loader = gen_batches(en_test_data,de_test_data,64)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:16:05.994749Z","iopub.status.busy":"2023-12-10T20:16:05.994440Z","iopub.status.idle":"2023-12-10T20:16:06.033309Z","shell.execute_reply":"2023-12-10T20:16:06.032364Z","shell.execute_reply.started":"2023-12-10T20:16:05.994724Z"},"trusted":true},"outputs":[],"source":["import torch \n","import torch.nn as nn\n","\n","class MultiHeadAttentionLayer(nn.Module):\n","    def __init__(self, hidden_size, n_heads, dropout):\n","        super().__init__()\n","        \n","        assert hidden_size % n_heads == 0\n","        \n","        self.hidden_size = hidden_size\n","        self.n_heads = n_heads\n","        self.head_size = hidden_size // n_heads\n","        \n","        self.fc_query = nn.Linear(hidden_size, hidden_size)\n","        self.fc_key = nn.Linear(hidden_size, hidden_size)\n","        self.fc_value = nn.Linear(hidden_size, hidden_size)\n","        self.fc_out = nn.Linear(hidden_size, hidden_size)\n","    \n","        self.dp = nn.Dropout(dropout)\n","        \n","        self.coefficient = torch.sqrt(torch.FloatTensor([self.head_size])).cuda()\n","        \n","    def forward(self, query, key, value, mask=None):\n","        b_size = query.shape[0]\n","   \n","        query_output = self.fc_query(query)\n","        key_output = self.fc_key(key)\n","        value_output = self.fc_value(value)\n","     \n","        query_output = query_output.view(b_size, -1, self.n_heads, self.head_size).permute(0, 2, 1, 3)\n","        key_output = key_output.view(b_size, -1, self.n_heads, self.head_size).permute(0, 2, 1, 3)\n","        value_output = value_output.view(b_size, -1, self.n_heads, self.head_size).permute(0, 2, 1, 3)\n","      \n","        energy = torch.matmul(query_output, key_output.permute(0, 1, 3, 2)) / self.coefficient\n","        if mask is not None:\n","            energy = energy.masked_fill(mask == 0, -1e10)\n","        \n","        attention = torch.softmax(energy, dim = -1)    \n","        output = torch.matmul(self.dp(attention), value_output)\n","        output = output.permute(0, 2, 1, 3).contiguous()\n","        output = output.view(b_size, -1, self.hidden_size)  \n","        output = self.fc_out(output)\n","        return output, attention\n","\n","\n","\n","class FeedForwardLayer(nn.Module):\n","    def __init__(self, hidden_size, ff_size, dropout):\n","        super().__init__()\n","\n","        self.ff_layer = nn.Sequential(\n","            nn.Linear(hidden_size, ff_size),\n","            nn.ReLU(),\n","            \n","            nn.Dropout(dropout),\n","            nn.Linear(ff_size, hidden_size)\n","        )\n","        \n","    def forward(self, input):\n","        output = self.ff_layer(input)\n","        return output\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, hidden_size, n_heads, ff_size,  dropout):\n","        super().__init__()\n","        \n","        self.self_atten = MultiHeadAttentionLayer(hidden_size, n_heads, dropout)\n","        self.self_atten_norm = nn.LayerNorm(hidden_size)\n","        self.ff_layer = FeedForwardLayer(hidden_size, ff_size, dropout)\n","        self.dp = nn.Dropout(dropout)\n","        self.ff_layer_norm = nn.LayerNorm(hidden_size)\n","        \n","    def forward(self, input, input_mask):\n","        #self attention\n","        atten_result, _ = self.self_atten(input, input, input, input_mask)\n","        \n","        atten_norm = self.self_atten_norm(input + self.dp(atten_result))\n","        ff_result = self.ff_layer(atten_norm)\n","        \n","        output = self.ff_layer_norm(atten_norm + self.dp(ff_result))\n","        return output\n","\n","class Encoder(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layers, n_heads, ff_size,dropout, MAX_LENGTH=100):\n","        super().__init__()\n","\n","        \n","        self.te = nn.Embedding(input_size, hidden_size)\n","        self.pe = nn.Embedding(MAX_LENGTH, hidden_size)\n","        \n","        encoding_layers = []\n","        for _ in range(n_layers):\n","            encoding_layers.append(EncoderLayer(hidden_size, n_heads, ff_size, dropout))\n","        self.encode_sequence = nn.Sequential(*encoding_layers)\n","        \n","        self.dp = nn.Dropout(dropout)\n","        \n","        self.coefficient = torch.sqrt(torch.FloatTensor([hidden_size])).cuda()\n","        \n","    def forward(self, input, input_mask):\n","        b_size = input.shape[0]\n","        input_size = input.shape[1]\n","        \n","        pos = torch.arange(0, input_size).unsqueeze(0).repeat(b_size, 1).cuda()\n","        input = self.dp((self.te(input) * self.coefficient) + self.pe(pos))\n","\n","        for layer in self.encode_sequence:\n","            input = layer(input, input_mask)\n","  \n","        return input\n","\n","class DecoderLayer(nn.Module):\n","    def __init__(self, hidden_size, n_heads, ff_size, dropout):\n","        super().__init__()\n","        \n","        self.self_atten = MultiHeadAttentionLayer(hidden_size, n_heads, dropout)\n","        self.self_atten_norm = nn.LayerNorm(hidden_size)\n","        self.encoder_atten = MultiHeadAttentionLayer(hidden_size, n_heads, dropout)\n","        self.encoder_atten_norm = nn.LayerNorm(hidden_size)\n","        self.ff_layer = FeedForwardLayer(hidden_size, ff_size, dropout)\n","        self.ff_layer_norm = nn.LayerNorm(hidden_size)\n","        self.dp = nn.Dropout(dropout)\n","        \n","    def forward(self, target, encoded_input, target_mask, input_mask):\n","        #self attention\n","        atten_result, _ = self.self_atten(target, target, target, target_mask)\n","        \n","        atten_norm = self.self_atten_norm(target + self.dp(atten_result))\n","\n","        atten_encoded, attention = self.encoder_atten(atten_norm, encoded_input, encoded_input, input_mask)\n","        \n","        encoded_norm = self.encoder_atten_norm(atten_norm + self.dp(atten_encoded))\n","\n","        ff_result = self.ff_layer(encoded_norm)\n","\n","        output = self.ff_layer_norm(encoded_norm + self.dp(ff_result))\n","\n","        return output, attention\n","\n","class Decoder(nn.Module):\n","    def __init__(self, output_size, hidden_size, n_layers, n_heads, ff_size, dropout, MAX_LENGTH=100):\n","        super().__init__()\n","        \n","        self.te = nn.Embedding(output_size, hidden_size)\n","        self.pe = nn.Embedding(MAX_LENGTH, hidden_size)\n","\n","        decoding_layers = []\n","        for _ in range(n_layers):\n","            decoding_layers.append(DecoderLayer(hidden_size, n_heads, ff_size, dropout))\n","        \n","        self.decode_sequence = nn.Sequential(*decoding_layers) \n","        \n","        self.fc_out = nn.Linear(hidden_size, output_size)\n","        \n","        self.dp = nn.Dropout(dropout)\n","        \n","        self.coefficient = torch.sqrt(torch.FloatTensor([hidden_size])).cuda()\n","        \n","    def forward(self, target, encoded_input, target_mask, input_mask):    \n","        b_size = target.shape[0]\n","        target_size = target.shape[1]\n","        \n","        pos = torch.arange(0, target_size).unsqueeze(0).repeat(b_size, 1).cuda()\n","        target = self.dp((self.te(target) * self.coefficient) + self.pe(pos))\n","        for layer in self.decode_sequence:\n","            target, attention = layer(target, encoded_input, target_mask, input_mask)\n","\n","        output = self.fc_out(target)\n","        return output, attention\n","\n","class Transformer(nn.Module):\n","    def __init__(self, encoder, decoder, padding_index=0):\n","        super().__init__()\n","        \n","        self.encoder = encoder\n","        self.decoder = decoder\n","        self.padding_index = padding_index\n","        \n","    def make_input_mask(self, input):\n","\n","        input_mask = (input != self.padding_index).unsqueeze(1).unsqueeze(2)\n","        return input_mask\n","    \n","    def make_target_mask(self, target):\n","\n","        target_pad_mask = (target != self.padding_index).unsqueeze(1).unsqueeze(2)\n","        target_sub_mask = torch.tril(torch.ones((target.shape[1], target.shape[1]))).bool().cuda()\n","        target_mask = target_pad_mask & target_sub_mask\n","        return target_mask\n","\n","    def forward(self, input, target):   \n","        input_mask = self.make_input_mask(input)\n","        target_mask = self.make_target_mask(target)\n","\n","        #encoder feed through\n","        encoded_input = self.encoder(input, input_mask)\n","\n","        #decoder feed_through\n","        output, attention = self.decoder(target, encoded_input, target_mask, input_mask)\n","\n","        return output, attention"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:16:06.035524Z","iopub.status.busy":"2023-12-10T20:16:06.034429Z","iopub.status.idle":"2023-12-10T20:16:06.207821Z","shell.execute_reply":"2023-12-10T20:16:06.206886Z","shell.execute_reply.started":"2023-12-10T20:16:06.035497Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["54433\n"]}],"source":["# print(en_word_index)\n","print(de_word_count)\n","\n","encoder_part = Encoder(en_word_count, 64, 3, 8, 128, 0.1)\n","decoder_part = Decoder(de_word_count, 64, 3, 8, 128, 0.1)\n","\n","transformer = Transformer(encoder_part, decoder_part, PAD).cuda()"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:16:06.209302Z","iopub.status.busy":"2023-12-10T20:16:06.208975Z","iopub.status.idle":"2023-12-10T20:16:06.219288Z","shell.execute_reply":"2023-12-10T20:16:06.218421Z","shell.execute_reply.started":"2023-12-10T20:16:06.209276Z"},"trusted":true},"outputs":[],"source":["def initialize_weights(model):\n","        if hasattr(model, 'weight') and model.weight.dim() > 1:\n","            nn.init.xavier_uniform_(model.weight.data)\n","\n","import torch.optim as optim\n","transformer.apply(initialize_weights)\n","loss_func = nn.CrossEntropyLoss(ignore_index=PAD)\n","optimizer = optim.Adam(transformer.parameters(), lr=0.0005)"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:16:06.220916Z","iopub.status.busy":"2023-12-10T20:16:06.220651Z","iopub.status.idle":"2023-12-10T20:16:06.227246Z","shell.execute_reply":"2023-12-10T20:16:06.226384Z","shell.execute_reply.started":"2023-12-10T20:16:06.220893Z"},"trusted":true},"outputs":[],"source":["def evaluate():\n","    shuffle(test_data_loader)\n","    test_loss = 0\n","    print(\"evaluating on test data\")\n","    for input, target in tqdm(test_data_loader):\n","        \n","        #pass through transformer\n","        output, _ = transformer(input, target[:,:-1])\n","        output_dim = output.shape[-1]\n","\n","        #flatten and omit SOS from target\n","        output = output.contiguous().view(-1, output_dim)\n","        target = target[:,1:].contiguous().view(-1)\n","\n","        #loss\n","        loss = loss_func(output, target)\n","        test_loss += loss\n","               \n","    return test_loss.item()"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T19:30:19.021537Z","iopub.status.busy":"2023-12-10T19:30:19.020657Z","iopub.status.idle":"2023-12-10T19:30:19.049049Z","shell.execute_reply":"2023-12-10T19:30:19.047844Z","shell.execute_reply.started":"2023-12-10T19:30:19.021504Z"},"trusted":true},"outputs":[{"ename":"NameError","evalue":"name 'epoch' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define the path for saving the model\u001b[39;00m\n\u001b[1;32m      4\u001b[0m model_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/kaggle/working/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 5\u001b[0m model_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(model_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformer_model_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mepoch\u001b[49m))\n","\u001b[0;31mNameError\u001b[0m: name 'epoch' is not defined"]}],"source":["import os\n","\n","# Define the path for saving the model\n","model_dir = '/kaggle/working/'\n","model_filename = os.path.join(model_dir, 'transformer_model_{}.pt'.format(epoch))\n","\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:16:06.228564Z","iopub.status.busy":"2023-12-10T20:16:06.228318Z","iopub.status.idle":"2023-12-10T20:16:06.239345Z","shell.execute_reply":"2023-12-10T20:16:06.238471Z","shell.execute_reply.started":"2023-12-10T20:16:06.228541Z"},"trusted":true},"outputs":[],"source":["def calculate_accuracy(output, target):\n","    # Convert output probabilities to predicted class (argmax over output dimension)\n","    predictions = output.argmax(dim=1, keepdim=True)\n","    # Compare with actual classes\n","    correct = predictions.eq(target.view_as(predictions)).sum()\n","    # Calculate accuracy\n","    acc = correct.float() / target.shape[0]\n","    return acc\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T20:16:06.241015Z","iopub.status.busy":"2023-12-10T20:16:06.240712Z","iopub.status.idle":"2023-12-10T21:05:01.013556Z","shell.execute_reply":"2023-12-10T21:05:01.012595Z","shell.execute_reply.started":"2023-12-10T20:16:06.240990Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:13<00:00, 40.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 0, Time: 73s, Estimated 1460 seconds remaining.\n","\tTraining Loss: 4.2732, Training Accuracy: 27.90%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 3.3129, Test Accuracy: 35.43%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 1, Time: 71s, Estimated 1349 seconds remaining.\n","\tTraining Loss: 2.9130, Training Accuracy: 38.27%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 97.33it/s] \n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.8211, Test Accuracy: 39.68%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 2, Time: 72s, Estimated 1296 seconds remaining.\n","\tTraining Loss: 2.4456, Training Accuracy: 41.68%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 107.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.6105, Test Accuracy: 41.53%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 3, Time: 71s, Estimated 1207 seconds remaining.\n","\tTraining Loss: 2.1534, Training Accuracy: 43.75%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 107.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5018, Test Accuracy: 42.68%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 4, Time: 71s, Estimated 1136 seconds remaining.\n","\tTraining Loss: 1.9523, Training Accuracy: 45.16%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 104.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4472, Test Accuracy: 43.13%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 5, Time: 72s, Estimated 1080 seconds remaining.\n","\tTraining Loss: 1.8040, Training Accuracy: 46.22%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4149, Test Accuracy: 43.51%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 6, Time: 71s, Estimated 994 seconds remaining.\n","\tTraining Loss: 1.6888, Training Accuracy: 47.07%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4024, Test Accuracy: 43.90%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 7, Time: 71s, Estimated 923 seconds remaining.\n","\tTraining Loss: 1.5984, Training Accuracy: 47.78%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 103.78it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.3869, Test Accuracy: 44.16%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 8, Time: 72s, Estimated 864 seconds remaining.\n","\tTraining Loss: 1.5257, Training Accuracy: 48.40%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 107.57it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4059, Test Accuracy: 44.09%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 9, Time: 71s, Estimated 781 seconds remaining.\n","\tTraining Loss: 1.4649, Training Accuracy: 48.95%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.33it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4053, Test Accuracy: 44.30%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.29it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 10, Time: 71s, Estimated 710 seconds remaining.\n","\tTraining Loss: 1.4143, Training Accuracy: 49.46%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 105.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4255, Test Accuracy: 44.35%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 11, Time: 72s, Estimated 648 seconds remaining.\n","\tTraining Loss: 1.3773, Training Accuracy: 49.81%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 103.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4243, Test Accuracy: 44.37%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 12, Time: 71s, Estimated 568 seconds remaining.\n","\tTraining Loss: 1.3417, Training Accuracy: 50.18%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4363, Test Accuracy: 44.43%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.20it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 13, Time: 71s, Estimated 497 seconds remaining.\n","\tTraining Loss: 1.3151, Training Accuracy: 50.47%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 105.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4460, Test Accuracy: 44.46%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 14, Time: 72s, Estimated 432 seconds remaining.\n","\tTraining Loss: 1.2904, Training Accuracy: 50.71%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4649, Test Accuracy: 44.39%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 15, Time: 71s, Estimated 355 seconds remaining.\n","\tTraining Loss: 1.2710, Training Accuracy: 50.93%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4765, Test Accuracy: 44.42%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.09it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 16, Time: 71s, Estimated 284 seconds remaining.\n","\tTraining Loss: 1.2526, Training Accuracy: 51.12%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 104.79it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4825, Test Accuracy: 44.29%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 17, Time: 71s, Estimated 213 seconds remaining.\n","\tTraining Loss: 1.2369, Training Accuracy: 51.33%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.38it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4801, Test Accuracy: 44.54%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 18, Time: 71s, Estimated 142 seconds remaining.\n","\tTraining Loss: 1.2235, Training Accuracy: 51.46%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4987, Test Accuracy: 44.36%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 19, Time: 71s, Estimated 71 seconds remaining.\n","\tTraining Loss: 1.2100, Training Accuracy: 51.59%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 104.53it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4986, Test Accuracy: 44.40%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 20, Time: 72s, Estimated 0 seconds remaining.\n","\tTraining Loss: 1.1982, Training Accuracy: 51.75%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.4994, Test Accuracy: 44.46%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 21, Time: 71s, Estimated -71 seconds remaining.\n","\tTraining Loss: 1.1866, Training Accuracy: 51.87%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 107.36it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5107, Test Accuracy: 44.40%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 22, Time: 71s, Estimated -142 seconds remaining.\n","\tTraining Loss: 1.1767, Training Accuracy: 51.99%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 104.50it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5123, Test Accuracy: 44.38%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.00it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 23, Time: 72s, Estimated -216 seconds remaining.\n","\tTraining Loss: 1.1666, Training Accuracy: 52.09%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5122, Test Accuracy: 44.50%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 24, Time: 71s, Estimated -284 seconds remaining.\n","\tTraining Loss: 1.1584, Training Accuracy: 52.18%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 107.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5045, Test Accuracy: 44.57%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 25, Time: 72s, Estimated -360 seconds remaining.\n","\tTraining Loss: 1.1504, Training Accuracy: 52.27%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 107.11it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5121, Test Accuracy: 44.44%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 26, Time: 71s, Estimated -426 seconds remaining.\n","\tTraining Loss: 1.1429, Training Accuracy: 52.34%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 104.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5179, Test Accuracy: 44.40%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 27, Time: 71s, Estimated -497 seconds remaining.\n","\tTraining Loss: 1.1352, Training Accuracy: 52.46%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.04it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5175, Test Accuracy: 44.51%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.31it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 28, Time: 71s, Estimated -568 seconds remaining.\n","\tTraining Loss: 1.1285, Training Accuracy: 52.51%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 105.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5252, Test Accuracy: 44.44%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.07it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 29, Time: 71s, Estimated -639 seconds remaining.\n","\tTraining Loss: 1.1226, Training Accuracy: 52.60%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.03it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5379, Test Accuracy: 44.38%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.32it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 30, Time: 71s, Estimated -710 seconds remaining.\n","\tTraining Loss: 1.1166, Training Accuracy: 52.66%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.54it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5406, Test Accuracy: 44.46%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.08it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 31, Time: 71s, Estimated -781 seconds remaining.\n","\tTraining Loss: 1.1115, Training Accuracy: 52.72%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 104.65it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5449, Test Accuracy: 44.50%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:12<00:00, 40.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 32, Time: 72s, Estimated -864 seconds remaining.\n","\tTraining Loss: 1.1065, Training Accuracy: 52.78%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 108.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5431, Test Accuracy: 44.34%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 33, Time: 71s, Estimated -923 seconds remaining.\n","\tTraining Loss: 1.1024, Training Accuracy: 52.82%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 109.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5433, Test Accuracy: 44.38%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.17it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 34, Time: 71s, Estimated -994 seconds remaining.\n","\tTraining Loss: 1.0956, Training Accuracy: 52.92%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.02it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5509, Test Accuracy: 44.43%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.06it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 35, Time: 71s, Estimated -1065 seconds remaining.\n","\tTraining Loss: 1.0912, Training Accuracy: 52.95%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.96it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5431, Test Accuracy: 44.42%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 36, Time: 71s, Estimated -1136 seconds remaining.\n","\tTraining Loss: 1.0869, Training Accuracy: 53.01%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 104.30it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5582, Test Accuracy: 44.54%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 37, Time: 71s, Estimated -1207 seconds remaining.\n","\tTraining Loss: 1.0837, Training Accuracy: 53.04%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 103.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5541, Test Accuracy: 44.51%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.05it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 38, Time: 71s, Estimated -1278 seconds remaining.\n","\tTraining Loss: 1.0799, Training Accuracy: 53.08%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 101.95it/s]\n"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5544, Test Accuracy: 44.44%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 2952/2952 [01:11<00:00, 41.10it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: 39, Time: 71s, Estimated -1349 seconds remaining.\n","\tTraining Loss: 1.0761, Training Accuracy: 53.12%\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 156/156 [00:01<00:00, 106.42it/s]"]},{"name":"stdout","output_type":"stream","text":["\tTest Loss: 2.5527, Test Accuracy: 44.37%\n","Training finished!\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import time\n","from random import shuffle\n","\n","\n","import torch\n","\n","# Function to convert data to tensor and move to GPU if available\n","def to_tensor_and_device(data):\n","    if not torch.is_tensor(data):\n","        data = torch.LongTensor(data)\n","    if torch.cuda.is_available():\n","        data = data.cuda()\n","    return data\n","\n","# Convert and move your data\n","en_test_data = to_tensor_and_device(en_test_data)\n","de_test_data = to_tensor_and_device(de_test_data)\n","\n","for epoch in range(40):\n","    shuffle(data_loader)\n","    shuffle(test_data_loader)\n","    train_loss = 0\n","    train_acc = 0\n","    start_time = time.time()\n","    \n","    for input, target in tqdm(data_loader):\n","        optimizer.zero_grad()\n","\n","        # Pass through transformer\n","        output, _ = transformer(input, target[:,:-1])\n","        output_dim = output.shape[-1]\n","\n","        # Flatten and omit SOS from target\n","        output = output.contiguous().view(-1, output_dim)\n","        target = target[:,1:].contiguous().view(-1)\n","\n","        # Loss\n","        loss = loss_func(output, target)\n","\n","        # Backpropagation\n","        loss.backward()\n","        nn.utils.clip_grad_norm_(transformer.parameters(), 1)\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        train_acc += calculate_accuracy(output, target).item()\n","\n","    train_loss /= len(data_loader)\n","    train_acc /= len(data_loader)\n","    end_time = int(time.time() - start_time)\n","\n","    \n","\n","   \n","    print(f'Epoch: {epoch}, Time: {end_time}s, Estimated {(20-epoch)*end_time} seconds remaining.')\n","    print(f'\\tTraining Loss: {train_loss:.4f}, Training Accuracy: {train_acc * 100:.2f}%')\n","\n","    # Evaluate on test data\n","    test_loss = 0\n","    test_acc = 0\n","    with torch.no_grad():\n","        for input, target in tqdm(test_data_loader):\n","\n","            # Pass through transformer\n","            output, _ = transformer(input, target[:,:-1])\n","            output_dim = output.shape[-1]\n","\n","            # Flatten and omit SOS from target\n","            output = output.contiguous().view(-1, output_dim)\n","            target = target[:,1:].contiguous().view(-1)\n","\n","            # Loss\n","            loss = loss_func(output, target)\n","            test_loss += loss.item()\n","            test_acc += calculate_accuracy(output, target).item()\n","\n","    test_loss /= len(test_data_loader)\n","    test_acc /= len(test_data_loader)\n","    print(f'\\tTest Loss: {test_loss:.4f}, Test Accuracy: {test_acc * 100:.2f}%')\n","\n","print('Training finished!')"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-12-10T21:06:30.633578Z","iopub.status.busy":"2023-12-10T21:06:30.632853Z","iopub.status.idle":"2023-12-10T21:06:30.928368Z","shell.execute_reply":"2023-12-10T21:06:30.927417Z","shell.execute_reply.started":"2023-12-10T21:06:30.633546Z"},"trusted":true},"outputs":[{"data":{"text/plain":["0"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4099111,"sourceId":7109567,"sourceType":"datasetVersion"},{"datasetId":4114864,"sourceId":7131911,"sourceType":"datasetVersion"}],"dockerImageVersionId":30616,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":5}
