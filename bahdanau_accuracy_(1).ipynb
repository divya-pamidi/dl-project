{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7123204,
          "sourceType": "datasetVersion",
          "datasetId": 4108869
        },
        {
          "sourceId": 7123365,
          "sourceType": "datasetVersion",
          "datasetId": 4108996
        },
        {
          "sourceId": 7126236,
          "sourceType": "datasetVersion",
          "datasetId": 4110894
        }
      ],
      "dockerImageVersionId": 30616,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.statmt.org/europarl/v7/fr-en.tgz\n",
        "!tar -xf fr-en.tgz"
      ],
      "metadata": {
        "id": "-Q8qvHO86ErV",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:07:04.804784Z",
          "iopub.execute_input": "2023-12-10T16:07:04.805782Z",
          "iopub.status.idle": "2023-12-10T16:07:26.794523Z",
          "shell.execute_reply.started": "2023-12-10T16:07:04.805733Z",
          "shell.execute_reply": "2023-12-10T16:07:26.793213Z"
        },
        "trusted": true,
        "outputId": "5804bed0-2e6b-448d-b08c-f91484434b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2023-12-10 16:07:05--  https://www.statmt.org/europarl/v7/fr-en.tgz\nResolving www.statmt.org (www.statmt.org)... 129.215.32.28\nConnecting to www.statmt.org (www.statmt.org)|129.215.32.28|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 202718517 (193M) [application/x-gzip]\nSaving to: ‘fr-en.tgz’\n\nfr-en.tgz           100%[===================>] 193.33M  14.2MB/s    in 14s     \n\n2023-12-10 16:07:20 (13.4 MB/s) - ‘fr-en.tgz’ saved [202718517/202718517]\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://download.pytorch.org/tutorial/data.zip\n",
        "!unzip data.zip"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T16:07:26.796791Z",
          "iopub.execute_input": "2023-12-10T16:07:26.797141Z",
          "iopub.status.idle": "2023-12-10T16:07:28.971548Z",
          "shell.execute_reply.started": "2023-12-10T16:07:26.797108Z",
          "shell.execute_reply": "2023-12-10T16:07:28.970633Z"
        },
        "trusted": true,
        "id": "Wmti4qCezE_F",
        "outputId": "0d82541a-7fa5-49bb-f4ab-a4145fc4b63a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "--2023-12-10 16:07:27--  https://download.pytorch.org/tutorial/data.zip\nResolving download.pytorch.org (download.pytorch.org)... 13.224.14.120, 13.224.14.44, 13.224.14.23, ...\nConnecting to download.pytorch.org (download.pytorch.org)|13.224.14.120|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2882130 (2.7M) [application/zip]\nSaving to: ‘data.zip’\n\ndata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.06s   \n\n2023-12-10 16:07:27 (43.7 MB/s) - ‘data.zip’ saved [2882130/2882130]\n\nArchive:  data.zip\n   creating: data/\n  inflating: data/eng-fra.txt        \n   creating: data/names/\n  inflating: data/names/Arabic.txt   \n  inflating: data/names/Chinese.txt  \n  inflating: data/names/Czech.txt    \n  inflating: data/names/Dutch.txt    \n  inflating: data/names/English.txt  \n  inflating: data/names/French.txt   \n  inflating: data/names/German.txt   \n  inflating: data/names/Greek.txt    \n  inflating: data/names/Irish.txt    \n  inflating: data/names/Italian.txt  \n  inflating: data/names/Japanese.txt  \n  inflating: data/names/Korean.txt   \n  inflating: data/names/Polish.txt   \n  inflating: data/names/Portuguese.txt  \n  inflating: data/names/Russian.txt  \n  inflating: data/names/Scottish.txt  \n  inflating: data/names/Spanish.txt  \n  inflating: data/names/Vietnamese.txt  \n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import unicode_literals, print_function, division\n",
        "from io import open\n",
        "import unicodedata\n",
        "import re\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "Adeguggm6ErZ",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:07:28.973238Z",
          "iopub.execute_input": "2023-12-10T16:07:28.973724Z",
          "iopub.status.idle": "2023-12-10T16:07:31.900726Z",
          "shell.execute_reply.started": "2023-12-10T16:07:28.973683Z",
          "shell.execute_reply": "2023-12-10T16:07:31.899866Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import pickle\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "file = open('europarl-v7.fr-en.en', mode='rt', encoding='utf-8')\n",
        "t = file.read()\n",
        "file.close()\n",
        "sentences = t.strip().split('\\n')\n",
        "new_s = []\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    for s in sentences:\n",
        "        s = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n",
        "        s = s.decode('UTF-8')\n",
        "        s = s.split()\n",
        "        s = [w.lower() for w in s]\n",
        "        s = [w.translate(table) for w in s]\n",
        "        s = [re_print.sub('', w) for w in s]\n",
        "        s = [wa for w in s if w.isalpha()]\n",
        "        new_s.append(' '.join(s))\n",
        "pickle.dump(new_s, open(filename, 'wb'))\n",
        "print('Saved: %s' % filename)\n",
        "for i in range(10):\n",
        "    print(new_s[i])\n",
        "\n",
        "file = open('europarl-v7.fr-en.fr', mode='rt', encoding='utf-8')\n",
        "t = file.read()\n",
        "file.close()\n",
        "sentences = t.strip().split('\\n')\n",
        "new_s = []\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    for s in sentences:\n",
        "        s = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n",
        "        s = s.decode('UTF-8')\n",
        "        s = s.split()\n",
        "        s = [w.lower() for w in s]\n",
        "        s = [w.translate(table) for w in s]\n",
        "        s = [re_print.sub('', w) for w in s]\n",
        "        s = [wa for w in s if w.isalpha()]\n",
        "        new_s.append(' '.join(s))\n",
        "pickle.dump(new_s, open(filename, 'wb'))\n",
        "print('Saved: %s' % filename)\n",
        "for i in range(1):\n",
        "    print(new_s[i])\n",
        "\n",
        "with open('french.pkl', 'rb') as f:\n",
        "    fr = pickle.load(f)\n",
        "\n",
        "with open('english.pkl', 'rb') as f:\n",
        "    eng = pickle.load(f)\n",
        "\n",
        "data = pd.DataFrame(zip(eng, fr), columns = ['English', 'French'])\n",
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T16:07:31.903265Z",
          "iopub.execute_input": "2023-12-10T16:07:31.903770Z",
          "iopub.status.idle": "2023-12-10T16:10:08.274997Z",
          "shell.execute_reply.started": "2023-12-10T16:07:31.903724Z",
          "shell.execute_reply": "2023-12-10T16:10:08.274049Z"
        },
        "trusted": true,
        "id": "wTeRMYeXzE_I",
        "outputId": "efa38a54-ebf0-4ad8-b6c1-eabfcfe9cd21"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Saved: english.pkl\nresumption of the session\ni declare resumed the session of the european parliament adjourned on friday december and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\nalthough as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\nyou have requested a debate on this subject in the course of the next few days during this partsession\nin the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\nplease rise then for this minute s silence\nthe house rose and observed a minute s silence\nmadam president on a point of order\nyou will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\none of the people assassinated very recently in sri lanka was mr kumar ponnambalam who had visited the european parliament just a few months ago\nSaved: french.pkl\nreprise de la session\n",
          "output_type": "stream"
        },
        {
          "execution_count": 4,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2007718  i would also like although they are absent to ...   \n2007719  i am not going to reopen the millennium or not...   \n2007720                         adjournment of the session   \n2007721  i declare the session of the european parliame...   \n2007722                       the sitting was closed at am   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2007718  je me permettrai meme bien quils soient absent...  \n2007719  je ne rouvrirai pas le debat sur le millenaire...  \n2007720                         interruption de la session  \n2007721  je declare interrompue la session du parlement...  \n2007722                              la seance est levee a  \n\n[2007723 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2007718</th>\n      <td>i would also like although they are absent to ...</td>\n      <td>je me permettrai meme bien quils soient absent...</td>\n    </tr>\n    <tr>\n      <th>2007719</th>\n      <td>i am not going to reopen the millennium or not...</td>\n      <td>je ne rouvrirai pas le debat sur le millenaire...</td>\n    </tr>\n    <tr>\n      <th>2007720</th>\n      <td>adjournment of the session</td>\n      <td>interruption de la session</td>\n    </tr>\n    <tr>\n      <th>2007721</th>\n      <td>i declare the session of the european parliame...</td>\n      <td>je declare interrompue la session du parlement...</td>\n    </tr>\n    <tr>\n      <th>2007722</th>\n      <td>the sitting was closed at am</td>\n      <td>la seance est levee a</td>\n    </tr>\n  </tbody>\n</table>\n<p>2007723 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = pd.read_csv('./data/eng-fra.txt', delimiter='\\t', names = ['English', 'French'])\n",
        "data2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:08.276307Z",
          "iopub.execute_input": "2023-12-10T16:10:08.276858Z",
          "iopub.status.idle": "2023-12-10T16:10:08.494198Z",
          "shell.execute_reply.started": "2023-12-10T16:10:08.276817Z",
          "shell.execute_reply": "2023-12-10T16:10:08.493313Z"
        },
        "trusted": true,
        "id": "QlLetJ40zE_I",
        "outputId": "00786de6-5f1d-4283-e577-9875dba8f109"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                  English  \\\n0                                                     Go.   \n1                                                    Run!   \n2                                                    Run!   \n3                                                    Wow!   \n4                                                   Fire!   \n...                                                   ...   \n135837  A carbon footprint is the amount of carbon dio...   \n135838  Death is something that we're often discourage...   \n135839  Since there are usually multiple websites on a...   \n135840  If someone who doesn't know your background sa...   \n135841  It may be impossible to get a completely error...   \n\n                                                   French  \n0                                                    Va !  \n1                                                 Cours !  \n2                                                Courez !  \n3                                              Ça alors !  \n4                                                Au feu !  \n...                                                   ...  \n135837  Une empreinte carbone est la somme de pollutio...  \n135838  La mort est une chose qu'on nous décourage sou...  \n135839  Puisqu'il y a de multiples sites web sur chaqu...  \n135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n135841  Il est peut-être impossible d'obtenir un Corpu...  \n\n[135842 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Va !</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135837</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>135838</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>135839</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>135840</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>135841</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>135842 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.concat([data,data2], ignore_index= True, axis = 0)\n",
        "\n",
        "data.to_csv('eng-fra.txt')\n",
        "data"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:08.495706Z",
          "iopub.execute_input": "2023-12-10T16:10:08.496102Z",
          "iopub.status.idle": "2023-12-10T16:10:40.016827Z",
          "shell.execute_reply.started": "2023-12-10T16:10:08.496067Z",
          "shell.execute_reply": "2023-12-10T16:10:40.015902Z"
        },
        "trusted": true,
        "id": "ww9Mbig8zE_I",
        "outputId": "fcbd6431-f4cd-43a4-de75-a7f3f8939797"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 6,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2143560  A carbon footprint is the amount of carbon dio...   \n2143561  Death is something that we're often discourage...   \n2143562  Since there are usually multiple websites on a...   \n2143563  If someone who doesn't know your background sa...   \n2143564  It may be impossible to get a completely error...   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2143560  Une empreinte carbone est la somme de pollutio...  \n2143561  La mort est une chose qu'on nous décourage sou...  \n2143562  Puisqu'il y a de multiples sites web sur chaqu...  \n2143563  Si quelqu'un qui ne connaît pas vos antécédent...  \n2143564  Il est peut-être impossible d'obtenir un Corpu...  \n\n[2143565 rows x 2 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2143560</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>2143561</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>2143562</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>2143563</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>2143564</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2143565 rows × 2 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_token = 0\n",
        "EOS_token = 1\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.w2i = {}\n",
        "        self.w2c = {}\n",
        "        self.i2w = {0: \"SOS\", 1: \"EOS\"}\n",
        "        self.num_of_W = 2\n",
        "\n",
        "    def insertSeq(self, seq):\n",
        "        for word in seq.split(' '):\n",
        "            self.insertWord(word)\n",
        "\n",
        "    def insertWord(self, word):\n",
        "        if word not in self.w2i:\n",
        "            self.w2i[word] = self.num_of_W\n",
        "            self.w2c[word] = 1\n",
        "            self.i2w[self.num_of_W] = word\n",
        "            self.num_of_W += 1\n",
        "        else:\n",
        "            self.w2c[word] += 1"
      ],
      "metadata": {
        "id": "_cu_CsEp6Erb",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:40.018022Z",
          "iopub.execute_input": "2023-12-10T16:10:40.018317Z",
          "iopub.status.idle": "2023-12-10T16:10:40.025442Z",
          "shell.execute_reply.started": "2023-12-10T16:10:40.018291Z",
          "shell.execute_reply": "2023-12-10T16:10:40.024590Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def removeNonLettersAndLowercase(s):\n",
        "    s = ''.join(c for c in unicodedata.normalize('NFD', s.lower().strip()) if unicodedata.category(c) != 'Mn')\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
        "    return s.strip()"
      ],
      "metadata": {
        "id": "khOeQvBO6Erc",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:40.026759Z",
          "iopub.execute_input": "2023-12-10T16:10:40.027094Z",
          "iopub.status.idle": "2023-12-10T16:10:40.036057Z",
          "shell.execute_reply.started": "2023-12-10T16:10:40.027063Z",
          "shell.execute_reply": "2023-12-10T16:10:40.035337Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rVocs(Voc1, Voc2, reverse=False):\n",
        "    print(\"Reading lines...\")\n",
        "\n",
        "    lines = open('data/%s-%s.txt' % (Voc1, Voc2), encoding='utf-8').read().strip().split('\\n')\n",
        "    pairs = [[removeNonLettersAndLowercase(s) for s in l.split('\\t')] for l in lines]\n",
        "    if reverse:\n",
        "        pairs = [list(reversed(p)) for p in pairs]\n",
        "        i_Voc = Voc(Voc2)\n",
        "        o_Voc = Voc(Voc1)\n",
        "    else:\n",
        "        i_Voc = Voc(Voc1)\n",
        "        o_Voc = Voc(Voc2)\n",
        "\n",
        "    return i_Voc, o_Voc, pairs"
      ],
      "metadata": {
        "id": "BFigR6o96Erd",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:40.037111Z",
          "iopub.execute_input": "2023-12-10T16:10:40.037363Z",
          "iopub.status.idle": "2023-12-10T16:10:40.049659Z",
          "shell.execute_reply.started": "2023-12-10T16:10:40.037341Z",
          "shell.execute_reply": "2023-12-10T16:10:40.048694Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = 20\n"
      ],
      "metadata": {
        "id": "lPTw_SKM6Erd",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:40.053236Z",
          "iopub.execute_input": "2023-12-10T16:10:40.053547Z",
          "iopub.status.idle": "2023-12-10T16:10:40.060849Z",
          "shell.execute_reply.started": "2023-12-10T16:10:40.053511Z",
          "shell.execute_reply": "2023-12-10T16:10:40.059958Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def processData(Voc1, Voc2, reverse=False):\n",
        "    i_Voc, o_Voc, pairs = rVocs(Voc1, Voc2, reverse)\n",
        "    print(\"Read %s sentence pairs\" % len(pairs))\n",
        "    pairs = [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]\n",
        "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
        "    print(\"Counting words...\")\n",
        "    for pair in pairs:\n",
        "        i_Voc.insertSeq(pair[0])\n",
        "        o_Voc.insertSeq(pair[1])\n",
        "    print(i_Voc.name, i_Voc.num_of_W)\n",
        "    print(o_Voc.name, o_Voc.num_of_W)\n",
        "    return i_Voc, o_Voc, pairs\n",
        "\n",
        "i_Voc, o_Voc, pairs = processData('eng', 'fra', True)\n",
        "print(random.choice(pairs))"
      ],
      "metadata": {
        "id": "Y51T0f4y6Erd",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:40.061938Z",
          "iopub.execute_input": "2023-12-10T16:10:40.062219Z",
          "iopub.status.idle": "2023-12-10T16:10:48.535572Z",
          "shell.execute_reply.started": "2023-12-10T16:10:40.062194Z",
          "shell.execute_reply": "2023-12-10T16:10:48.534677Z"
        },
        "trusted": true,
        "outputId": "e64fb335-4ec1-44c6-b402-a535b3efc4bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Reading lines...\nRead 135842 sentence pairs\nTrimmed to 135283 sentence pairs\nCounting words...\nCounted words:\nfra 21170\neng 12917\n['tu devrais prendre un parapluie au cas ou', 'just to be on the safe side why don t you take an umbrella with you ?']\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, i_s, h_s, dropout_p=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.h_s = h_s\n",
        "        self.embedding = nn.Embedding(i_s, h_s)\n",
        "        self.gru = nn.GRU(h_s, h_s, batch_first=True)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, input):\n",
        "        embedded = self.dropout(self.embedding(input))\n",
        "        o, hidden = self.gru(embedded)\n",
        "        return o, hidden"
      ],
      "metadata": {
        "id": "AcFjkArk6Ere",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:48.536970Z",
          "iopub.execute_input": "2023-12-10T16:10:48.537680Z",
          "iopub.status.idle": "2023-12-10T16:10:48.544186Z",
          "shell.execute_reply.started": "2023-12-10T16:10:48.537640Z",
          "shell.execute_reply": "2023-12-10T16:10:48.543266Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, h_s, o_s):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(o_s, h_s)\n",
        "        self.gru = nn.GRU(h_s, h_s, batch_first=True)\n",
        "        self.out = nn.Linear(h_s, o_s)\n",
        "\n",
        "    def forward(self, e_o, e_h, t_t=None):\n",
        "        batch_size = e_o.size(0)\n",
        "        d_i = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        d_h = e_h\n",
        "        d_os = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            d_o, d_h  = self.forward(d_i, d_h)\n",
        "            d_os.append(d_o)\n",
        "\n",
        "            if t_t is not None:\n",
        "                d_i = t_t[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                _, topi = d_o.topk(1)\n",
        "                d_i = topi.squeeze(-1).detach()\n",
        "\n",
        "        d_os = torch.cat(d_os, dim=1)\n",
        "        d_os = F.log_softmax(d_os, dim=-1)\n",
        "        return d_os, d_h, None\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        o = self.embedding(input)\n",
        "        o = F.relu(o)\n",
        "        o, hidden = self.gru(o, hidden)\n",
        "        o = self.out(o)\n",
        "        return o, hidden"
      ],
      "metadata": {
        "id": "zQHn6WhS6Ere",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:48.545494Z",
          "iopub.execute_input": "2023-12-10T16:10:48.545779Z",
          "iopub.status.idle": "2023-12-10T16:10:48.558891Z",
          "shell.execute_reply.started": "2023-12-10T16:10:48.545754Z",
          "shell.execute_reply": "2023-12-10T16:10:48.558061Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    def __init__(self, h_s):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.Wa = nn.Linear(h_s, h_s)\n",
        "        self.Ua = nn.Linear(h_s, h_s)\n",
        "        self.Va = nn.Linear(h_s, 1)\n",
        "\n",
        "    def forward(self, query, keys):\n",
        "        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "\n",
        "        weights = F.softmax(scores, dim=-1)\n",
        "        context = torch.bmm(weights, keys)\n",
        "\n",
        "        return context, weights\n",
        "\n",
        "class AttnDecoder(nn.Module):\n",
        "    def __init__(self, h_s, o_s, dropout_p=0.1):\n",
        "        super(AttnDecoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(o_s, h_s)\n",
        "        self.attention = BahdanauAttention(h_s)\n",
        "        self.gru = nn.GRU(2 * h_s, h_s, batch_first=True)\n",
        "        self.out = nn.Linear(h_s, o_s)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "\n",
        "    def forward(self, e_o, e_h, t_t=None):\n",
        "        batch_size = e_o.size(0)\n",
        "        d_i = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n",
        "        d_h = e_h\n",
        "        d_os = []\n",
        "        attentions = []\n",
        "\n",
        "        for i in range(MAX_LENGTH):\n",
        "            d_o, d_h, attn_weights = self.forward(\n",
        "                d_i, d_h, e_o\n",
        "            )\n",
        "            d_os.append(d_o)\n",
        "            attentions.append(attn_weights)\n",
        "\n",
        "            if t_t is not None:\n",
        "                d_i = t_t[:, i].unsqueeze(1)\n",
        "            else:\n",
        "                _, topi = d_o.topk(1)\n",
        "                d_i = topi.squeeze(-1).detach()\n",
        "\n",
        "        d_os = torch.cat(d_os, dim=1)\n",
        "        d_os = F.log_softmax(d_os, dim=-1)\n",
        "        attentions = torch.cat(attentions, dim=1)\n",
        "\n",
        "        return d_os, d_h, attentions\n",
        "\n",
        "\n",
        "    def forward(self, input, hidden, e_o):\n",
        "        embedded =  self.dropout(self.embedding(input))\n",
        "\n",
        "        query = hidden.permute(1, 0, 2)\n",
        "        context, attn_weights = self.attention(query, e_o)\n",
        "        input_gru = torch.cat((embedded, context), dim=2)\n",
        "\n",
        "        o, hidden = self.gru(input_gru, hidden)\n",
        "        o = self.out(o)\n",
        "\n",
        "        return o, hidden, attn_weights"
      ],
      "metadata": {
        "id": "-ISlNZMh6Ere",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:48.559950Z",
          "iopub.execute_input": "2023-12-10T16:10:48.560253Z",
          "iopub.status.idle": "2023-12-10T16:10:48.575366Z",
          "shell.execute_reply.started": "2023-12-10T16:10:48.560219Z",
          "shell.execute_reply": "2023-12-10T16:10:48.574626Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def i_f_s(Voc, sentence):\n",
        "    return [Voc.w2i[word] for word in sentence.split(' ')]\n",
        "\n",
        "def t_f_s(Voc, sentence):\n",
        "    indexes = i_f_s(Voc, sentence)\n",
        "    indexes.append(EOS_token)\n",
        "    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n",
        "\n",
        "def t_f_p(pair):\n",
        "    i_t = t_f_s(i_Voc, pair[0])\n",
        "    t_t = t_f_s(o_Voc, pair[1])\n",
        "    return (i_t, t_t)\n",
        "\n",
        "def get_data(batch_size):\n",
        "    i_Voc, o_Voc, pairs = processData('eng', 'fra', True)\n",
        "\n",
        "    n = len(pairs)\n",
        "    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n",
        "\n",
        "    for idx, (inp, tgt) in enumerate(pairs):\n",
        "        inp_ids = i_f_s(i_Voc, inp)\n",
        "        tgt_ids = i_f_s(o_Voc, tgt)\n",
        "        inp_ids.append(EOS_token)\n",
        "        tgt_ids.append(EOS_token)\n",
        "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
        "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
        "\n",
        "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
        "                               torch.LongTensor(target_ids).to(device))\n",
        "\n",
        "    train_pairs, test_pairs = train_test_split(train_data, test_size=0.3, random_state=42)\n",
        "    val_pairs, test_pairs = train_test_split(test_pairs, test_size=0.5, random_state=42)\n",
        "    print('len of training samples ', len(train_pairs))\n",
        "\n",
        "\n",
        "    train_dataloader = DataLoader(train_pairs, batch_size=batch_size, shuffle= True)\n",
        "    test_dataloader = DataLoader(test_pairs, batch_size=batch_size, shuffle= True)\n",
        "    val_dataloader = DataLoader(val_pairs, batch_size=batch_size, shuffle= True)\n",
        "    return i_Voc, o_Voc, train_dataloader, test_dataloader, val_dataloader"
      ],
      "metadata": {
        "id": "sPNXQFYE6Erf",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:48.576481Z",
          "iopub.execute_input": "2023-12-10T16:10:48.576755Z",
          "iopub.status.idle": "2023-12-10T16:10:49.037121Z",
          "shell.execute_reply.started": "2023-12-10T16:10:48.576727Z",
          "shell.execute_reply": "2023-12-10T16:10:49.036241Z"
        },
        "trusted": true,
        "outputId": "3746ec42-cd09-4e5c-829d-fb04bfb291ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    for data in dataloader:\n",
        "        i_t, t_t = data\n",
        "\n",
        "        encoder_optimizer.zero_grad()\n",
        "        decoder_optimizer.zero_grad()\n",
        "\n",
        "        e_o, e_h = encoder(i_t)\n",
        "        d_os, _, _ = decoder(e_o, e_h, t_t)\n",
        "\n",
        "        _, predicted = d_os.max(dim=2)\n",
        "        correct = (predicted == t_t)\n",
        "        accuracy = correct.sum().item() / (t_t.size(0) * t_t.size(1))\n",
        "\n",
        "        loss = criterion(\n",
        "            d_os.view(-1, d_os.size(-1)),\n",
        "            t_t.view(-1)\n",
        "        )\n",
        "        loss.backward()\n",
        "\n",
        "        encoder_optimizer.step()\n",
        "        decoder_optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader), accuracy"
      ],
      "metadata": {
        "id": "90_8nbNu6Erf",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.038257Z",
          "iopub.execute_input": "2023-12-10T16:10:49.038538Z",
          "iopub.status.idle": "2023-12-10T16:10:49.046057Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.038513Z",
          "shell.execute_reply": "2023-12-10T16:10:49.045174Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
        "          decoder_optimizer, criterion):\n",
        "\n",
        "    total_loss = 0\n",
        "    #encoder.eval()\n",
        "    #decoder.eval()\n",
        "    for data in dataloader:\n",
        "        i_t, t_t = data\n",
        "\n",
        "\n",
        "        e_o, e_h = encoder(i_t)\n",
        "        d_os, _, _ = decoder(e_o, e_h, t_t)\n",
        "\n",
        "        loss = criterion(\n",
        "            d_os.view(-1, d_os.size(-1)),\n",
        "            t_t.view(-1)\n",
        "        )\n",
        "\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.047185Z",
          "iopub.execute_input": "2023-12-10T16:10:49.047477Z",
          "iopub.status.idle": "2023-12-10T16:10:49.058528Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.047446Z",
          "shell.execute_reply": "2023-12-10T16:10:49.057574Z"
        },
        "trusted": true,
        "id": "hy36xsPpzE_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import math\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
      ],
      "metadata": {
        "id": "QBlTyz3l6Erf",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.059802Z",
          "iopub.execute_input": "2023-12-10T16:10:49.060380Z",
          "iopub.status.idle": "2023-12-10T16:10:49.069056Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.060346Z",
          "shell.execute_reply": "2023-12-10T16:10:49.068290Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "def train(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
        "               print_every=100, plot_every=100):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    plt_val_losses = []\n",
        "    accuracies = []\n",
        "    print_loss_total = 0\n",
        "    plot_loss_total = 0\n",
        "    plt_val_loss = 0\n",
        "    print_val_loss_total = 0\n",
        "\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
        "\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        val_loss = evaluate_epoch(val_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "        print_loss_total += loss\n",
        "        print_val_loss_total += val_loss\n",
        "        plot_loss_total += loss\n",
        "\n",
        "        if epoch % print_every == 0:\n",
        "            print_loss_avg = print_loss_total / print_every\n",
        "            val_loss_avg = print_val_loss_total / print_every\n",
        "            print_loss_total = 0\n",
        "            print_val_loss_total = 0\n",
        "            print('%s (%d %d %d%% ) %.4f' % (timeSince(start, epoch / n_epochs),\n",
        "                                        epoch, epoch / n_epochs * 100, print_loss_avg, val_loss_avg))\n",
        "            print('training_loss ', print_loss_avg, 'val_loss_avg ', val_loss_avg, ' accuracy ', accuracy)\n",
        "\n",
        "        if epoch % plot_every == 0:\n",
        "            plot_loss_avg = plot_loss_total / plot_every\n",
        "            plot_losses.append(plot_loss_avg)\n",
        "            plt_val_avg = print_val_loss_total / plot_every\n",
        "            plt_val_losses.append(plt_val_avg)\n",
        "            accuracies.append(accuracy)\n",
        "\n",
        "            plot_loss_total = 0\n",
        "            print_val_loss_total = 0\n",
        "    showPlot(plot_losses)\n",
        "    showPlot(plt_val_losses)\n",
        "    showPlot(accuracies)"
      ],
      "metadata": {
        "id": "rgeA21XG6Erf",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.070171Z",
          "iopub.execute_input": "2023-12-10T16:10:49.070664Z",
          "iopub.status.idle": "2023-12-10T16:10:49.082598Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.070639Z",
          "shell.execute_reply": "2023-12-10T16:10:49.081761Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.switch_backend('agg')\n",
        "import matplotlib.ticker as ticker\n",
        "import numpy as np\n",
        "\n",
        "def showPlot(points):\n",
        "    plt.figure()\n",
        "    fig, ax = plt.subplots()\n",
        "    loc = ticker.MultipleLocator(base=0.2)\n",
        "    ax.yaxis.set_major_locator(loc)\n",
        "    plt.plot(points)"
      ],
      "metadata": {
        "id": "n7eKAVeu6Erf",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.083628Z",
          "iopub.execute_input": "2023-12-10T16:10:49.083913Z",
          "iopub.status.idle": "2023-12-10T16:10:49.096824Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.083880Z",
          "shell.execute_reply": "2023-12-10T16:10:49.096035Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n",
        "    with torch.no_grad():\n",
        "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
        "\n",
        "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
        "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
        "\n",
        "        _, topi = decoder_outputs.topk(1)\n",
        "        decoded_ids = topi.squeeze()\n",
        "\n",
        "        decoded_words = []\n",
        "        for idx in decoded_ids:\n",
        "            if idx.item() == EOS_token:\n",
        "                decoded_words.append('<EOS>')\n",
        "                break\n",
        "            decoded_words.append(output_lang.index2word[idx.item()])\n",
        "    return decoded_words, decoder_attn"
      ],
      "metadata": {
        "id": "obs79dIc6Erg",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.097900Z",
          "iopub.execute_input": "2023-12-10T16:10:49.098148Z",
          "iopub.status.idle": "2023-12-10T16:10:49.108529Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.098125Z",
          "shell.execute_reply": "2023-12-10T16:10:49.107612Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateRandomly(encoder, decoder, n=10):\n",
        "    for i in range(n):\n",
        "        pair = random.choice(pairs)\n",
        "        print('>', pair[0])\n",
        "        print('=', pair[1])\n",
        "        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n",
        "        output_sentence = ' '.join(output_words)\n",
        "        print('<', output_sentence)\n",
        "        print('')"
      ],
      "metadata": {
        "id": "bNtYCKlt6Erg",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.109433Z",
          "iopub.execute_input": "2023-12-10T16:10:49.109660Z",
          "iopub.status.idle": "2023-12-10T16:10:49.118797Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.109639Z",
          "shell.execute_reply": "2023-12-10T16:10:49.117940Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(pairs))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.119849Z",
          "iopub.execute_input": "2023-12-10T16:10:49.120100Z",
          "iopub.status.idle": "2023-12-10T16:10:49.129681Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.120078Z",
          "shell.execute_reply": "2023-12-10T16:10:49.128803Z"
        },
        "trusted": true,
        "id": "kgjk0I5QzE_R",
        "outputId": "28ba7b4a-5432-4236-9506-a105ce56b215"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "135283\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 128\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "\n",
        "input_lang, output_lang, train_dataloader, test_dataloader, val_dataloader = get_dataloader(batch_size)\n",
        "\n",
        "encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
        "decoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n",
        "\n",
        "train(train_dataloader, encoder, decoder, 20, print_every=1, plot_every=5)"
      ],
      "metadata": {
        "id": "D30x7eXm6Erj",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:10:49.130702Z",
          "iopub.execute_input": "2023-12-10T16:10:49.130973Z",
          "iopub.status.idle": "2023-12-10T16:56:59.887798Z",
          "shell.execute_reply.started": "2023-12-10T16:10:49.130943Z",
          "shell.execute_reply": "2023-12-10T16:56:59.886383Z"
        },
        "trusted": true,
        "outputId": "89ef8d9b-267c-4caa-bed4-a6c37b97542a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Reading lines...\nRead 135842 sentence pairs\nTrimmed to 135283 sentence pairs\nCounting words...\nCounted words:\nfra 21170\neng 12917\nlen of training samples  94698\n2m 18s (- 44m 0s) (1 5 1% ) 1.1320\ntraining_loss  1.533872699999326 val_loss_avg  1.1319529556342074  accuracy  0.735\n4m 37s (- 41m 40s) (2 10 1% ) 0.8429\ntraining_loss  1.0121917736087296 val_loss_avg  0.8428726548882755  accuracy  0.825\n6m 55s (- 39m 14s) (3 15 0% ) 0.6806\ntraining_loss  0.7973666756036314 val_loss_avg  0.6805990667459932  accuracy  0.835\n9m 13s (- 36m 55s) (4 20 0% ) 0.5806\ntraining_loss  0.6694069208929667 val_loss_avg  0.5805689741731496  accuracy  0.9\n11m 32s (- 34m 36s) (5 25 0% ) 0.5119\ntraining_loss  0.5843993532597214 val_loss_avg  0.5118590659487087  accuracy  0.905\n13m 50s (- 32m 16s) (6 30 0% ) 0.4617\ntraining_loss  0.5238899617984488 val_loss_avg  0.46167325418744537  accuracy  0.92\n16m 8s (- 29m 58s) (7 35 0% ) 0.4203\ntraining_loss  0.477090929317716 val_loss_avg  0.42033322806394585  accuracy  0.905\n18m 27s (- 27m 40s) (8 40 0% ) 0.3868\ntraining_loss  0.4400490918574301 val_loss_avg  0.38683545359888594  accuracy  0.925\n20m 44s (- 25m 21s) (9 45 0% ) 0.3625\ntraining_loss  0.4087949366535287 val_loss_avg  0.362482646203323  accuracy  0.855\n23m 2s (- 23m 2s) (10 50 0% ) 0.3394\ntraining_loss  0.3834151884037498 val_loss_avg  0.3393530702520464  accuracy  0.925\n25m 20s (- 20m 44s) (11 55 0% ) 0.3220\ntraining_loss  0.3617400398679279 val_loss_avg  0.3219581982825656  accuracy  0.94\n27m 40s (- 18m 26s) (12 60 0% ) 0.3055\ntraining_loss  0.3429574555490871 val_loss_avg  0.30547427253646625  accuracy  0.92\n29m 57s (- 16m 7s) (13 65 0% ) 0.2907\ntraining_loss  0.3270902132816814 val_loss_avg  0.2907209709034981  accuracy  0.945\n32m 14s (- 13m 48s) (14 70 0% ) 0.2811\ntraining_loss  0.31318648970509705 val_loss_avg  0.28109467242013764  accuracy  0.955\n34m 30s (- 11m 30s) (15 75 0% ) 0.2690\ntraining_loss  0.30039959399382005 val_loss_avg  0.26896922143327223  accuracy  0.955\n36m 47s (- 9m 11s) (16 80 0% ) 0.2588\ntraining_loss  0.29005512928942573 val_loss_avg  0.2588495521680326  accuracy  0.945\n39m 4s (- 6m 53s) (17 85 0% ) 0.2502\ntraining_loss  0.2792086020212721 val_loss_avg  0.2502074012784539  accuracy  0.97\n41m 20s (- 4m 35s) (18 90 0% ) 0.2425\ntraining_loss  0.2705105227846149 val_loss_avg  0.24250024329820596  accuracy  0.935\n43m 38s (- 2m 17s) (19 95 0% ) 0.2357\ntraining_loss  0.2629459274907571 val_loss_avg  0.23574159986566048  accuracy  0.955\n45m 54s (- 0m 0s) (20 100 0% ) 0.2306\ntraining_loss  0.25481003899177584 val_loss_avg  0.23059459937031607  accuracy  0.89\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set dropout layers to ``eval`` mode\n",
        "\n"
      ],
      "metadata": {
        "id": "T_GvV-IP6Erj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoder.eval()\n",
        "decoder.eval()\n",
        "evaluateRandomly(encoder, decoder)"
      ],
      "metadata": {
        "id": "aOMAx0tP6Erj",
        "execution": {
          "iopub.status.busy": "2023-12-10T16:56:59.889956Z",
          "iopub.execute_input": "2023-12-10T16:56:59.890792Z",
          "iopub.status.idle": "2023-12-10T16:57:00.044532Z",
          "shell.execute_reply.started": "2023-12-10T16:56:59.890740Z",
          "shell.execute_reply": "2023-12-10T16:57:00.043645Z"
        },
        "trusted": true,
        "outputId": "34994806-1cba-4e73-90d8-e6c3b8fac9ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "> ils sont similaires\n= they re similar\n< they appreciate motion <EOS>\n\n> mangez vous du riz tous les jours ?\n= do you eat rice every day ?\n< do you eat rice every day ? <EOS>\n\n> je me rappelle lui avoir donne la cle\n= i remember that i gave him the key\n< i remember him the key key the key <EOS>\n\n> papa s assure que toutes les lampes sont deja eteintes avant d aller dormir\n= papa made sure all the lights were turned off before going to bed\n< papa made sure everything the lights are already going to go before they go to sleep <EOS>\n\n> je ne suis pas heureux\n= i m not happy\n< i m not happy <EOS>\n\n> si tu te reposes tu seras bientot de nouveau sur pieds\n= if you rest you will be back on your feet again soon\n< if you rest of you will be back on your new side feet <EOS>\n\n> le medecin de tom lui a dit d arreter de fumer\n= tom s doctor told him to quit smoking\n< the doctor tried to told tom to stop smoking <EOS>\n\n> qu est ce que c est que ce barouf ?\n= what s the commotion ?\n< what s the commotion ? <EOS>\n\n> le navire arborait le pavillon etatsunien\n= the ship was flying the american flag\n< the ship was flying the american flag <EOS>\n\n> pourquoi voulez vous faire cela ?\n= why do you want to do this ?\n< how do you want to do this ? <EOS>\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(encoder.state_dict(), 'bahdanau_encoder_weights.pth')\n",
        "torch.save(decoder.state_dict(), 'bahdanau_decoder_weights.pth')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-10T16:57:00.045705Z",
          "iopub.execute_input": "2023-12-10T16:57:00.045987Z",
          "iopub.status.idle": "2023-12-10T16:57:00.100544Z",
          "shell.execute_reply.started": "2023-12-10T16:57:00.045962Z",
          "shell.execute_reply": "2023-12-10T16:57:00.099767Z"
        },
        "trusted": true,
        "id": "8TuPrgrfzE_R"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}