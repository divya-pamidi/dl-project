{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7123204,"sourceType":"datasetVersion","datasetId":4108869},{"sourceId":7123365,"sourceType":"datasetVersion","datasetId":4108996},{"sourceId":7126236,"sourceType":"datasetVersion","datasetId":4110894}],"dockerImageVersionId":30616,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://www.statmt.org/europarl/v7/fr-en.tgz\n!tar -xf fr-en.tgz\n# For tips on running notebooks in Google Colab, see\n# https://pytorch.org/tutorials/beginner/colab\n#%matplotlib inline","metadata":{"id":"-Q8qvHO86ErV","execution":{"iopub.status.busy":"2023-12-10T16:07:04.804784Z","iopub.execute_input":"2023-12-10T16:07:04.805782Z","iopub.status.idle":"2023-12-10T16:07:26.794523Z","shell.execute_reply.started":"2023-12-10T16:07:04.805733Z","shell.execute_reply":"2023-12-10T16:07:26.793213Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-12-10 16:07:05--  https://www.statmt.org/europarl/v7/fr-en.tgz\nResolving www.statmt.org (www.statmt.org)... 129.215.32.28\nConnecting to www.statmt.org (www.statmt.org)|129.215.32.28|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 202718517 (193M) [application/x-gzip]\nSaving to: ‘fr-en.tgz’\n\nfr-en.tgz           100%[===================>] 193.33M  14.2MB/s    in 14s     \n\n2023-12-10 16:07:20 (13.4 MB/s) - ‘fr-en.tgz’ saved [202718517/202718517]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://download.pytorch.org/tutorial/data.zip\n!unzip data.zip","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:07:26.796791Z","iopub.execute_input":"2023-12-10T16:07:26.797141Z","iopub.status.idle":"2023-12-10T16:07:28.971548Z","shell.execute_reply.started":"2023-12-10T16:07:26.797108Z","shell.execute_reply":"2023-12-10T16:07:28.970633Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2023-12-10 16:07:27--  https://download.pytorch.org/tutorial/data.zip\nResolving download.pytorch.org (download.pytorch.org)... 13.224.14.120, 13.224.14.44, 13.224.14.23, ...\nConnecting to download.pytorch.org (download.pytorch.org)|13.224.14.120|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2882130 (2.7M) [application/zip]\nSaving to: ‘data.zip’\n\ndata.zip            100%[===================>]   2.75M  --.-KB/s    in 0.06s   \n\n2023-12-10 16:07:27 (43.7 MB/s) - ‘data.zip’ saved [2882130/2882130]\n\nArchive:  data.zip\n   creating: data/\n  inflating: data/eng-fra.txt        \n   creating: data/names/\n  inflating: data/names/Arabic.txt   \n  inflating: data/names/Chinese.txt  \n  inflating: data/names/Czech.txt    \n  inflating: data/names/Dutch.txt    \n  inflating: data/names/English.txt  \n  inflating: data/names/French.txt   \n  inflating: data/names/German.txt   \n  inflating: data/names/Greek.txt    \n  inflating: data/names/Irish.txt    \n  inflating: data/names/Italian.txt  \n  inflating: data/names/Japanese.txt  \n  inflating: data/names/Korean.txt   \n  inflating: data/names/Polish.txt   \n  inflating: data/names/Portuguese.txt  \n  inflating: data/names/Russian.txt  \n  inflating: data/names/Scottish.txt  \n  inflating: data/names/Spanish.txt  \n  inflating: data/names/Vietnamese.txt  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n# NLP From Scratch: Translation with a Sequence to Sequence Network and Attention\n**Author**: [Sean Robertson](https://github.com/spro)\n\nThis is the third and final tutorial on doing \"NLP From Scratch\", where we\nwrite our own classes and functions to preprocess the data to do our NLP\nmodeling tasks. We hope after you complete this tutorial that you'll proceed to\nlearn how `torchtext` can handle much of this preprocessing for you in the\nthree tutorials immediately following this one.\n\nIn this project we will be teaching a neural network to translate from\nFrench to English.\n\n::\n\n    [KEY: > input, = target, < output]\n\n    > il est en train de peindre un tableau .\n    = he is painting a picture .\n    < he is painting a picture .\n\n    > pourquoi ne pas essayer ce vin delicieux ?\n    = why not try that delicious wine ?\n    < why not try that delicious wine ?\n\n    > elle n est pas poete mais romanciere .\n    = she is not a poet but a novelist .\n    < she not not a poet but a novelist .\n\n    > vous etes trop maigre .\n    = you re too skinny .\n    < you re all alone .\n\n... to varying degrees of success.\n\nThis is made possible by the simple but powerful idea of the [sequence\nto sequence network](https://arxiv.org/abs/1409.3215)_, in which two\nrecurrent neural networks work together to transform one sequence to\nanother. An encoder network condenses an input sequence into a vector,\nand a decoder network unfolds that vector into a new sequence.\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\nTo improve upon this model we'll use an [attention\nmechanism](https://arxiv.org/abs/1409.0473)_, which lets the decoder\nlearn to focus over a specific range of the input sequence.\n\n**Recommended Reading:**\n\nI assume you have at least installed PyTorch, know Python, and\nunderstand Tensors:\n\n-  https://pytorch.org/ For installation instructions\n-  :doc:`/beginner/deep_learning_60min_blitz` to get started with PyTorch in general\n-  :doc:`/beginner/pytorch_with_examples` for a wide and deep overview\n-  :doc:`/beginner/former_torchies_tutorial` if you are former Lua Torch user\n\n\nIt would also be useful to know about Sequence to Sequence networks and\nhow they work:\n\n-  [Learning Phrase Representations using RNN Encoder-Decoder for\n   Statistical Machine Translation](https://arxiv.org/abs/1406.1078)_\n-  [Sequence to Sequence Learning with Neural\n   Networks](https://arxiv.org/abs/1409.3215)_\n-  [Neural Machine Translation by Jointly Learning to Align and\n   Translate](https://arxiv.org/abs/1409.0473)_\n-  [A Neural Conversational Model](https://arxiv.org/abs/1506.05869)_\n\nYou will also find the previous tutorials on\n:doc:`/intermediate/char_rnn_classification_tutorial`\nand :doc:`/intermediate/char_rnn_generation_tutorial`\nhelpful as those concepts are very similar to the Encoder and Decoder\nmodels, respectively.\n\n**Requirements**\n","metadata":{"id":"BssEJUcU6ErX"}},{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"Adeguggm6ErZ","execution":{"iopub.status.busy":"2023-12-10T16:07:28.973238Z","iopub.execute_input":"2023-12-10T16:07:28.973724Z","iopub.status.idle":"2023-12-10T16:07:31.900726Z","shell.execute_reply.started":"2023-12-10T16:07:28.973683Z","shell.execute_reply":"2023-12-10T16:07:31.899866Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\nimport unicodedata\nimport pickle\nimport pandas as pd \n# load doc into memory\ndef load_doc(filename):\n\t# open the file as read only\n\tfile = open(filename, mode='rt', encoding='utf-8')\n\t# read all text\n\ttext = file.read()\n\t# close the file\n\tfile.close()\n\treturn text\n\n# split a loaded document into sentences\ndef to_sentences(doc):\n\treturn doc.strip().split('\\n')\n\n# clean a list of lines\ndef clean_lines(lines):\n\tcleaned = list()\n\t# prepare regex for char filtering\n\tre_print = re.compile('[^%s]' % re.escape(string.printable))\n\t# prepare translation table for removing punctuation\n\ttable = str.maketrans('', '', string.punctuation)\n\tfor line in lines:\n\t\t# normalize unicode characters\n\t\tline = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n\t\tline = line.decode('UTF-8')\n\t\t# tokenize on white space\n\t\tline = line.split()\n\t\t# convert to lower case\n\t\tline = [word.lower() for word in line]\n\t\t# remove punctuation from each token\n\t\tline = [word.translate(table) for word in line]\n\t\t# remove non-printable chars form each token\n\t\tline = [re_print.sub('', w) for w in line]\n\t\t# remove tokens with numbers in them\n\t\tline = [word for word in line if word.isalpha()]\n\t\t# store as string\n\t\tcleaned.append(' '.join(line))\n\treturn cleaned\n\n# save a list of clean sentences to file\ndef save_clean_sentences(sentences, filename):\n\tpickle.dump(sentences, open(filename, 'wb'))\n\tprint('Saved: %s' % filename)\n\n# load English data\nfilename = 'europarl-v7.fr-en.en'\ndoc = load_doc(filename)\nsentences = to_sentences(doc)\nsentences = clean_lines(sentences)\nsave_clean_sentences(sentences, 'english.pkl')\n# spot check\nfor i in range(10):\n\tprint(sentences[i])\n\n# load French data\nfilename = 'europarl-v7.fr-en.fr'\ndoc = load_doc(filename)\nsentences = to_sentences(doc)\nsentences = clean_lines(sentences)\nsave_clean_sentences(sentences, 'french.pkl')\n# spot check\nfor i in range(1):\n\tprint(sentences[i])\n#This will take our WMT2014 datasets and clean them of any punctuation, uppercase letters, non-printable characters, and tokens with numbers in them. Then it pickles the files for later use.\n\nwith open('french.pkl', 'rb') as f:\n    fr_voc = pickle.load(f)\n\nwith open('english.pkl', 'rb') as f:\n    eng_voc = pickle.load(f)\n    \ndata = pd.DataFrame(zip(eng_voc, fr_voc), columns = ['English', 'French'])\ndata","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:07:31.903265Z","iopub.execute_input":"2023-12-10T16:07:31.903770Z","iopub.status.idle":"2023-12-10T16:10:08.274997Z","shell.execute_reply.started":"2023-12-10T16:07:31.903724Z","shell.execute_reply":"2023-12-10T16:10:08.274049Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Saved: english.pkl\nresumption of the session\ni declare resumed the session of the european parliament adjourned on friday december and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\nalthough as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\nyou have requested a debate on this subject in the course of the next few days during this partsession\nin the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\nplease rise then for this minute s silence\nthe house rose and observed a minute s silence\nmadam president on a point of order\nyou will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\none of the people assassinated very recently in sri lanka was mr kumar ponnambalam who had visited the european parliament just a few months ago\nSaved: french.pkl\nreprise de la session\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2007718  i would also like although they are absent to ...   \n2007719  i am not going to reopen the millennium or not...   \n2007720                         adjournment of the session   \n2007721  i declare the session of the european parliame...   \n2007722                       the sitting was closed at am   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2007718  je me permettrai meme bien quils soient absent...  \n2007719  je ne rouvrirai pas le debat sur le millenaire...  \n2007720                         interruption de la session  \n2007721  je declare interrompue la session du parlement...  \n2007722                              la seance est levee a  \n\n[2007723 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2007718</th>\n      <td>i would also like although they are absent to ...</td>\n      <td>je me permettrai meme bien quils soient absent...</td>\n    </tr>\n    <tr>\n      <th>2007719</th>\n      <td>i am not going to reopen the millennium or not...</td>\n      <td>je ne rouvrirai pas le debat sur le millenaire...</td>\n    </tr>\n    <tr>\n      <th>2007720</th>\n      <td>adjournment of the session</td>\n      <td>interruption de la session</td>\n    </tr>\n    <tr>\n      <th>2007721</th>\n      <td>i declare the session of the european parliame...</td>\n      <td>je declare interrompue la session du parlement...</td>\n    </tr>\n    <tr>\n      <th>2007722</th>\n      <td>the sitting was closed at am</td>\n      <td>la seance est levee a</td>\n    </tr>\n  </tbody>\n</table>\n<p>2007723 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data2 = pd.read_csv('./data/eng-fra.txt', delimiter='\\t', names = ['English', 'French'])\ndata2","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:08.276307Z","iopub.execute_input":"2023-12-10T16:10:08.276858Z","iopub.status.idle":"2023-12-10T16:10:08.494198Z","shell.execute_reply.started":"2023-12-10T16:10:08.276817Z","shell.execute_reply":"2023-12-10T16:10:08.493313Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"                                                  English  \\\n0                                                     Go.   \n1                                                    Run!   \n2                                                    Run!   \n3                                                    Wow!   \n4                                                   Fire!   \n...                                                   ...   \n135837  A carbon footprint is the amount of carbon dio...   \n135838  Death is something that we're often discourage...   \n135839  Since there are usually multiple websites on a...   \n135840  If someone who doesn't know your background sa...   \n135841  It may be impossible to get a completely error...   \n\n                                                   French  \n0                                                    Va !  \n1                                                 Cours !  \n2                                                Courez !  \n3                                              Ça alors !  \n4                                                Au feu !  \n...                                                   ...  \n135837  Une empreinte carbone est la somme de pollutio...  \n135838  La mort est une chose qu'on nous décourage sou...  \n135839  Puisqu'il y a de multiples sites web sur chaqu...  \n135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n135841  Il est peut-être impossible d'obtenir un Corpu...  \n\n[135842 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Va !</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135837</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>135838</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>135839</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>135840</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>135841</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>135842 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([data,data2], ignore_index= True, axis = 0)\n\ndata.to_csv('eng-fra.txt')\ndata","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:08.495706Z","iopub.execute_input":"2023-12-10T16:10:08.496102Z","iopub.status.idle":"2023-12-10T16:10:40.016827Z","shell.execute_reply.started":"2023-12-10T16:10:08.496067Z","shell.execute_reply":"2023-12-10T16:10:40.015902Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2143560  A carbon footprint is the amount of carbon dio...   \n2143561  Death is something that we're often discourage...   \n2143562  Since there are usually multiple websites on a...   \n2143563  If someone who doesn't know your background sa...   \n2143564  It may be impossible to get a completely error...   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2143560  Une empreinte carbone est la somme de pollutio...  \n2143561  La mort est une chose qu'on nous décourage sou...  \n2143562  Puisqu'il y a de multiples sites web sur chaqu...  \n2143563  Si quelqu'un qui ne connaît pas vos antécédent...  \n2143564  Il est peut-être impossible d'obtenir un Corpu...  \n\n[2143565 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2143560</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>2143561</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>2143562</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>2143563</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>2143564</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2143565 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Loading data files\n\nThe data for this project is a set of many thousands of English to\nFrench translation pairs.\n\n[This question on Open Data Stack\nExchange](https://opendata.stackexchange.com/questions/3888/dataset-of-sentences-translated-into-many-languages)_\npointed me to the open translation site https://tatoeba.org/ which has\ndownloads available at https://tatoeba.org/eng/downloads - and better\nyet, someone did the extra work of splitting language pairs into\nindividual text files here: https://www.manythings.org/anki/\n\nThe English to French pairs are too big to include in the repository, so\ndownload to ``data/eng-fra.txt`` before continuing. The file is a tab\nseparated list of translation pairs:\n\n::\n\n    I am cold.    J'ai froid.\n\n.. Note::\n   Download the data from\n   [here](https://download.pytorch.org/tutorial/data.zip)\n   and extract it to the current directory.\n\n","metadata":{"id":"JWMnVZ816Era"}},{"cell_type":"markdown","source":"Similar to the character encoding used in the character-level RNN\ntutorials, we will be representing each word in a language as a one-hot\nvector, or giant vector of zeros except for a single one (at the index\nof the word). Compared to the dozens of characters that might exist in a\nlanguage, there are many many more words, so the encoding vector is much\nlarger. We will however cheat a bit and trim the data to only use a few\nthousand words per language.\n\n.. figure:: /_static/img/seq-seq-images/word-encoding.png\n   :alt:\n\n\n\n","metadata":{"id":"4oQNokeP6Erb"}},{"cell_type":"markdown","source":"We'll need a unique index per word to use as the inputs and targets of\nthe networks later. To keep track of all this we will use a helper class\ncalled ``Lang`` which has word → index (``word2index``) and index → word\n(``index2word``) dictionaries, as well as a count of each word\n``word2count`` which will be used to replace rare words later.\n\n\n","metadata":{"id":"iOQRwnaH6Erb"}},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\nclass Lang:\n    def __init__(self, name):\n        self.name = name\n        self.word2index = {}\n        self.word2count = {}\n        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n        self.n_words = 2  # Count SOS and EOS\n\n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n\n    def addWord(self, word):\n        if word not in self.word2index:\n            self.word2index[word] = self.n_words\n            self.word2count[word] = 1\n            self.index2word[self.n_words] = word\n            self.n_words += 1\n        else:\n            self.word2count[word] += 1","metadata":{"id":"_cu_CsEp6Erb","execution":{"iopub.status.busy":"2023-12-10T16:10:40.018022Z","iopub.execute_input":"2023-12-10T16:10:40.018317Z","iopub.status.idle":"2023-12-10T16:10:40.025442Z","shell.execute_reply.started":"2023-12-10T16:10:40.018291Z","shell.execute_reply":"2023-12-10T16:10:40.024590Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"The files are all in Unicode, to simplify we will turn Unicode\ncharacters to ASCII, make everything lowercase, and trim most\npunctuation.\n\n\n","metadata":{"id":"rMfOMlOU6Erc"}},{"cell_type":"code","source":"# Turn a Unicode string to plain ASCII, thanks to\n# https://stackoverflow.com/a/518232/2809427\ndef unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn'\n    )\n\n# Lowercase, trim, and remove non-letter characters\ndef normalizeString(s):\n    s = unicodeToAscii(s.lower().strip())\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n    return s.strip()","metadata":{"id":"khOeQvBO6Erc","execution":{"iopub.status.busy":"2023-12-10T16:10:40.026759Z","iopub.execute_input":"2023-12-10T16:10:40.027094Z","iopub.status.idle":"2023-12-10T16:10:40.036057Z","shell.execute_reply.started":"2023-12-10T16:10:40.027063Z","shell.execute_reply":"2023-12-10T16:10:40.035337Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"To read the data file we will split the file into lines, and then split\nlines into pairs. The files are all English → Other Language, so if we\nwant to translate from Other Language → English I added the ``reverse``\nflag to reverse the pairs.\n\n\n","metadata":{"id":"Wni1rxam6Erc"}},{"cell_type":"code","source":"def readLangs(lang1, lang2, reverse=False):\n    print(\"Reading lines...\")\n\n    # Read the file and split into lines\n    lines = open('data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n        read().strip().split('\\n')\n\n    # Split every line into pairs and normalize\n    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n\n    # Reverse pairs, make Lang instances\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        input_lang = Lang(lang2)\n        output_lang = Lang(lang1)\n    else:\n        input_lang = Lang(lang1)\n        output_lang = Lang(lang2)\n\n    return input_lang, output_lang, pairs","metadata":{"id":"BFigR6o96Erd","execution":{"iopub.status.busy":"2023-12-10T16:10:40.037111Z","iopub.execute_input":"2023-12-10T16:10:40.037363Z","iopub.status.idle":"2023-12-10T16:10:40.049659Z","shell.execute_reply.started":"2023-12-10T16:10:40.037341Z","shell.execute_reply":"2023-12-10T16:10:40.048694Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Since there are a *lot* of example sentences and we want to train\nsomething quickly, we'll trim the data set to only relatively short and\nsimple sentences. Here the maximum length is 10 words (that includes\nending punctuation) and we're filtering to sentences that translate to\nthe form \"I am\" or \"He is\" etc. (accounting for apostrophes replaced\nearlier).\n\n\n","metadata":{"id":"klXRpRSy6Erd"}},{"cell_type":"code","source":"MAX_LENGTH = 20\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < MAX_LENGTH and \\\n        len(p[1].split(' ')) < MAX_LENGTH #and \\\n        #p[1].startswith(eng_prefixes)\n\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]","metadata":{"id":"lPTw_SKM6Erd","execution":{"iopub.status.busy":"2023-12-10T16:10:40.053236Z","iopub.execute_input":"2023-12-10T16:10:40.053547Z","iopub.status.idle":"2023-12-10T16:10:40.060849Z","shell.execute_reply.started":"2023-12-10T16:10:40.053511Z","shell.execute_reply":"2023-12-10T16:10:40.059958Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"The full process for preparing the data is:\n\n-  Read text file and split into lines, split lines into pairs\n-  Normalize text, filter by length and content\n-  Make word lists from sentences in pairs\n\n\n","metadata":{"id":"GBsyGLja6Erd"}},{"cell_type":"code","source":"def prepareData(lang1, lang2, reverse=False):\n    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = filterPairs(pairs)\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        input_lang.addSentence(pair[0])\n        output_lang.addSentence(pair[1])\n    print(\"Counted words:\")\n    print(input_lang.name, input_lang.n_words)\n    print(output_lang.name, output_lang.n_words)\n    return input_lang, output_lang, pairs\n\ninput_lang, output_lang, pairs = prepareData('eng', 'fra', True)\nprint(random.choice(pairs))","metadata":{"id":"Y51T0f4y6Erd","execution":{"iopub.status.busy":"2023-12-10T16:10:40.061938Z","iopub.execute_input":"2023-12-10T16:10:40.062219Z","iopub.status.idle":"2023-12-10T16:10:48.535572Z","shell.execute_reply.started":"2023-12-10T16:10:40.062194Z","shell.execute_reply":"2023-12-10T16:10:48.534677Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 135283 sentence pairs\nCounting words...\nCounted words:\nfra 21170\neng 12917\n['tu devrais prendre un parapluie au cas ou', 'just to be on the safe side why don t you take an umbrella with you ?']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## The Seq2Seq Model\n\nA Recurrent Neural Network, or RNN, is a network that operates on a\nsequence and uses its own output as input for subsequent steps.\n\nA [Sequence to Sequence network](https://arxiv.org/abs/1409.3215)_, or\nseq2seq network, or [Encoder Decoder\nnetwork](https://arxiv.org/pdf/1406.1078v3.pdf)_, is a model\nconsisting of two RNNs called the encoder and decoder. The encoder reads\nan input sequence and outputs a single vector, and the decoder reads\nthat vector to produce an output sequence.\n\n.. figure:: /_static/img/seq-seq-images/seq2seq.png\n   :alt:\n\nUnlike sequence prediction with a single RNN, where every input\ncorresponds to an output, the seq2seq model frees us from sequence\nlength and order, which makes it ideal for translation between two\nlanguages.\n\nConsider the sentence ``Je ne suis pas le chat noir`` → ``I am not the\nblack cat``. Most of the words in the input sentence have a direct\ntranslation in the output sentence, but are in slightly different\norders, e.g. ``chat noir`` and ``black cat``. Because of the ``ne/pas``\nconstruction there is also one more word in the input sentence. It would\nbe difficult to produce a correct translation directly from the sequence\nof input words.\n\nWith a seq2seq model the encoder creates a single vector which, in the\nideal case, encodes the \"meaning\" of the input sequence into a single\nvector — a single point in some N dimensional space of sentences.\n\n\n","metadata":{"id":"db9RnyFa6Erd"}},{"cell_type":"markdown","source":"### The Encoder\n\nThe encoder of a seq2seq network is a RNN that outputs some value for\nevery word from the input sentence. For every input word the encoder\noutputs a vector and a hidden state, and uses the hidden state for the\nnext input word.\n\n.. figure:: /_static/img/seq-seq-images/encoder-network.png\n   :alt:\n\n\n\n","metadata":{"id":"pR24Q10Q6Ere"}},{"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, dropout_p=0.1):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        output, hidden = self.gru(embedded)\n        return output, hidden","metadata":{"id":"AcFjkArk6Ere","execution":{"iopub.status.busy":"2023-12-10T16:10:48.536970Z","iopub.execute_input":"2023-12-10T16:10:48.537680Z","iopub.status.idle":"2023-12-10T16:10:48.544186Z","shell.execute_reply.started":"2023-12-10T16:10:48.537640Z","shell.execute_reply":"2023-12-10T16:10:48.543266Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"### The Decoder\n\nThe decoder is another RNN that takes the encoder output vector(s) and\noutputs a sequence of words to create the translation.\n\n\n","metadata":{"id":"yG90Oh_f6Ere"}},{"cell_type":"markdown","source":"#### Simple Decoder\n\nIn the simplest seq2seq decoder we use only last output of the encoder.\nThis last output is sometimes called the *context vector* as it encodes\ncontext from the entire sequence. This context vector is used as the\ninitial hidden state of the decoder.\n\nAt every step of decoding, the decoder is given an input token and\nhidden state. The initial input token is the start-of-string ``<SOS>``\ntoken, and the first hidden state is the context vector (the encoder's\nlast hidden state).\n\n.. figure:: /_static/img/seq-seq-images/decoder-network.png\n   :alt:\n\n\n\n","metadata":{"id":"HWOzXUxT6Ere"}},{"cell_type":"code","source":"class DecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size):\n        super(DecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden  = self.forward_step(decoder_input, decoder_hidden)\n            decoder_outputs.append(decoder_output)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        return decoder_outputs, decoder_hidden, None # We return `None` for consistency in the training loop\n\n    def forward_step(self, input, hidden):\n        output = self.embedding(input)\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n        output = self.out(output)\n        return output, hidden","metadata":{"id":"zQHn6WhS6Ere","execution":{"iopub.status.busy":"2023-12-10T16:10:48.545494Z","iopub.execute_input":"2023-12-10T16:10:48.545779Z","iopub.status.idle":"2023-12-10T16:10:48.558891Z","shell.execute_reply.started":"2023-12-10T16:10:48.545754Z","shell.execute_reply":"2023-12-10T16:10:48.558061Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"I encourage you to train and observe the results of this model, but to\nsave space we'll be going straight for the gold and introducing the\nAttention Mechanism.\n\n\n","metadata":{"id":"3ShhBLMv6Ere"}},{"cell_type":"markdown","source":"#### Attention Decoder\n\nIf only the context vector is passed between the encoder and decoder,\nthat single vector carries the burden of encoding the entire sentence.\n\nAttention allows the decoder network to \"focus\" on a different part of\nthe encoder's outputs for every step of the decoder's own outputs. First\nwe calculate a set of *attention weights*. These will be multiplied by\nthe encoder output vectors to create a weighted combination. The result\n(called ``attn_applied`` in the code) should contain information about\nthat specific part of the input sequence, and thus help the decoder\nchoose the right output words.\n\n.. figure:: https://i.imgur.com/1152PYf.png\n   :alt:\n\nCalculating the attention weights is done with another feed-forward\nlayer ``attn``, using the decoder's input and hidden state as inputs.\nBecause there are sentences of all sizes in the training data, to\nactually create and train this layer we have to choose a maximum\nsentence length (input length, for encoder outputs) that it can apply\nto. Sentences of the maximum length will use all the attention weights,\nwhile shorter sentences will only use the first few.\n\n.. figure:: /_static/img/seq-seq-images/attention-decoder-network.png\n   :alt:\n\n\nBahdanau attention, also known as additive attention, is a commonly used\nattention mechanism in sequence-to-sequence models, particularly in neural\nmachine translation tasks. It was introduced by Bahdanau et al. in their\npaper titled [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf)_.\nThis attention mechanism employs a learned alignment model to compute attention\nscores between the encoder and decoder hidden states. It utilizes a feed-forward\nneural network to calculate alignment scores.\n\nHowever, there are alternative attention mechanisms available, such as Luong attention,\nwhich computes attention scores by taking the dot product between the decoder hidden\nstate and the encoder hidden states. It does not involve the non-linear transformation\nused in Bahdanau attention.\n\nIn this tutorial, we will be using Bahdanau attention. However, it would be a valuable\nexercise to explore modifying the attention mechanism to use Luong attention.\n\n","metadata":{"id":"2SD9eXOW6Ere"}},{"cell_type":"code","source":"class BahdanauAttention(nn.Module):\n    def __init__(self, hidden_size):\n        super(BahdanauAttention, self).__init__()\n        self.Wa = nn.Linear(hidden_size, hidden_size)\n        self.Ua = nn.Linear(hidden_size, hidden_size)\n        self.Va = nn.Linear(hidden_size, 1)\n\n    def forward(self, query, keys):\n        scores = self.Va(torch.tanh(self.Wa(query) + self.Ua(keys)))\n        scores = scores.squeeze(2).unsqueeze(1)\n\n        weights = F.softmax(scores, dim=-1)\n        context = torch.bmm(weights, keys)\n\n        return context, weights\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n        super(AttnDecoderRNN, self).__init__()\n        self.embedding = nn.Embedding(output_size, hidden_size)\n        self.attention = BahdanauAttention(hidden_size)\n        self.gru = nn.GRU(2 * hidden_size, hidden_size, batch_first=True)\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n        batch_size = encoder_outputs.size(0)\n        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        decoder_hidden = encoder_hidden\n        decoder_outputs = []\n        attentions = []\n\n        for i in range(MAX_LENGTH):\n            decoder_output, decoder_hidden, attn_weights = self.forward_step(\n                decoder_input, decoder_hidden, encoder_outputs\n            )\n            decoder_outputs.append(decoder_output)\n            attentions.append(attn_weights)\n\n            if target_tensor is not None:\n                # Teacher forcing: Feed the target as the next input\n                decoder_input = target_tensor[:, i].unsqueeze(1) # Teacher forcing\n            else:\n                # Without teacher forcing: use its own predictions as the next input\n                _, topi = decoder_output.topk(1)\n                decoder_input = topi.squeeze(-1).detach()  # detach from history as input\n\n        decoder_outputs = torch.cat(decoder_outputs, dim=1)\n        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n        attentions = torch.cat(attentions, dim=1)\n\n        return decoder_outputs, decoder_hidden, attentions\n\n\n    def forward_step(self, input, hidden, encoder_outputs):\n        embedded =  self.dropout(self.embedding(input))\n\n        query = hidden.permute(1, 0, 2)\n        context, attn_weights = self.attention(query, encoder_outputs)\n        input_gru = torch.cat((embedded, context), dim=2)\n\n        output, hidden = self.gru(input_gru, hidden)\n        output = self.out(output)\n\n        return output, hidden, attn_weights","metadata":{"id":"-ISlNZMh6Ere","execution":{"iopub.status.busy":"2023-12-10T16:10:48.559950Z","iopub.execute_input":"2023-12-10T16:10:48.560253Z","iopub.status.idle":"2023-12-10T16:10:48.575366Z","shell.execute_reply.started":"2023-12-10T16:10:48.560219Z","shell.execute_reply":"2023-12-10T16:10:48.574626Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-info\"><h4>Note</h4><p>There are other forms of attention that work around the length\n  limitation by using a relative position approach. Read about \"local\n  attention\" in [Effective Approaches to Attention-based Neural Machine\n  Translation](https://arxiv.org/abs/1508.04025)_.</p></div>\n\n## Training\n\n### Preparing Training Data\n\nTo train, for each pair we will need an input tensor (indexes of the\nwords in the input sentence) and target tensor (indexes of the words in\nthe target sentence). While creating these vectors we will append the\nEOS token to both sequences.\n\n\n","metadata":{"id":"6iZcYzvl6Ere"}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef indexesFromSentence(lang, sentence):\n    return [lang.word2index[word] for word in sentence.split(' ')]\n\ndef tensorFromSentence(lang, sentence):\n    indexes = indexesFromSentence(lang, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef tensorsFromPair(pair):\n    input_tensor = tensorFromSentence(input_lang, pair[0])\n    target_tensor = tensorFromSentence(output_lang, pair[1])\n    return (input_tensor, target_tensor)\n\ndef get_dataloader(batch_size):\n    input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = indexesFromSentence(input_lang, inp)\n        tgt_ids = indexesFromSentence(output_lang, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n    \n    train_pairs, test_pairs = train_test_split(train_data, test_size=0.3, random_state=42)\n    val_pairs, test_pairs = train_test_split(test_pairs, test_size=0.5, random_state=42)\n    print('len of training samples ', len(train_pairs))\n\n    \n    train_dataloader = DataLoader(train_pairs, batch_size=batch_size, shuffle= True)\n    test_dataloader = DataLoader(test_pairs, batch_size=batch_size, shuffle= True)\n    val_dataloader = DataLoader(val_pairs, batch_size=batch_size, shuffle= True)                                        \n    return input_lang, output_lang, train_dataloader, test_dataloader, val_dataloader","metadata":{"id":"sPNXQFYE6Erf","execution":{"iopub.status.busy":"2023-12-10T16:10:48.576481Z","iopub.execute_input":"2023-12-10T16:10:48.576755Z","iopub.status.idle":"2023-12-10T16:10:49.037121Z","shell.execute_reply.started":"2023-12-10T16:10:48.576727Z","shell.execute_reply":"2023-12-10T16:10:49.036241Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training the Model\n\nTo train we run the input sentence through the encoder, and keep track\nof every output and the latest hidden state. Then the decoder is given\nthe ``<SOS>`` token as its first input, and the last hidden state of the\nencoder as its first hidden state.\n\n\"Teacher forcing\" is the concept of using the real target outputs as\neach next input, instead of using the decoder's guess as the next input.\nUsing teacher forcing causes it to converge faster but [when the trained\nnetwork is exploited, it may exhibit\ninstability](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.378.4095&rep=rep1&type=pdf)_.\n\nYou can observe outputs of teacher-forced networks that read with\ncoherent grammar but wander far from the correct translation -\nintuitively it has learned to represent the output grammar and can \"pick\nup\" the meaning once the teacher tells it the first few words, but it\nhas not properly learned how to create the sentence from the translation\nin the first place.\n\nBecause of the freedom PyTorch's autograd gives us, we can randomly\nchoose to use teacher forcing or not with a simple if statement. Turn\n``teacher_forcing_ratio`` up to use more of it.\n\n\n","metadata":{"id":"FrhC8oZO6Erf"}},{"cell_type":"code","source":"def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    for data in dataloader:\n        input_tensor, target_tensor = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n        \n        _, predicted = decoder_outputs.max(dim=2)\n        correct = (predicted == target_tensor)\n        accuracy = correct.sum().item() / (target_tensor.size(0) * target_tensor.size(1))\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader), accuracy","metadata":{"id":"90_8nbNu6Erf","execution":{"iopub.status.busy":"2023-12-10T16:10:49.038257Z","iopub.execute_input":"2023-12-10T16:10:49.038538Z","iopub.status.idle":"2023-12-10T16:10:49.046057Z","shell.execute_reply.started":"2023-12-10T16:10:49.038513Z","shell.execute_reply":"2023-12-10T16:10:49.045174Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"def evaluate_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    #encoder.eval()\n    #decoder.eval()\n    for data in dataloader:\n        input_tensor, target_tensor = data\n\n        \n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n\n        loss = criterion(\n            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n            target_tensor.view(-1)\n        )\n\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:49.047185Z","iopub.execute_input":"2023-12-10T16:10:49.047477Z","iopub.status.idle":"2023-12-10T16:10:49.058528Z","shell.execute_reply.started":"2023-12-10T16:10:49.047446Z","shell.execute_reply":"2023-12-10T16:10:49.057574Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"This is a helper function to print time elapsed and estimated time\nremaining given the current time and progress %.\n\n\n","metadata":{"id":"94ufq5Ma6Erf"}},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"id":"QBlTyz3l6Erf","execution":{"iopub.status.busy":"2023-12-10T16:10:49.059802Z","iopub.execute_input":"2023-12-10T16:10:49.060380Z","iopub.status.idle":"2023-12-10T16:10:49.069056Z","shell.execute_reply.started":"2023-12-10T16:10:49.060346Z","shell.execute_reply":"2023-12-10T16:10:49.068290Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The whole training process looks like this:\n\n-  Start a timer\n-  Initialize optimizers and criterion\n-  Create set of training pairs\n-  Start empty losses array for plotting\n\nThen we call ``train`` many times and occasionally print the progress (%\nof examples, time so far, estimated time) and average loss.\n\n\n","metadata":{"id":"7EBldSYS6Erf"}},{"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR\n\ndef train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100):\n    start = time.time()\n    plot_losses = []\n    plt_val_losses = []\n    accuracies = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n    plt_val_loss = 0\n    print_val_loss_total = 0\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    \n    encoder_scheduler = StepLR(encoder_optimizer, step_size=5, gamma=0.5)\n    decoder_scheduler = StepLR(decoder_optimizer, step_size=5, gamma=0.5)\n    \n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        val_loss = evaluate_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        print_val_loss_total += val_loss\n        plot_loss_total += loss\n\n        if epoch % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            val_loss_avg = print_val_loss_total / print_every\n            print_loss_total = 0\n            print_val_loss_total = 0\n            print('%s (%d %d %d%% ) %.4f' % (timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, print_loss_avg, val_loss_avg))\n            print('training_loss ', print_loss_avg, 'val_loss_avg ', val_loss_avg, ' accuracy ', accuracy)\n\n        if epoch % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plt_val_avg = print_val_loss_total / plot_every\n            plt_val_losses.append(plt_val_avg)\n            accuracies.append(accuracy)\n            \n            plot_loss_total = 0\n            print_val_loss_total = 0\n    showPlot(plot_losses)\n    showPlot(plt_val_losses)\n    showPlot(accuracies)","metadata":{"id":"rgeA21XG6Erf","execution":{"iopub.status.busy":"2023-12-10T16:10:49.070171Z","iopub.execute_input":"2023-12-10T16:10:49.070664Z","iopub.status.idle":"2023-12-10T16:10:49.082598Z","shell.execute_reply.started":"2023-12-10T16:10:49.070639Z","shell.execute_reply":"2023-12-10T16:10:49.081761Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"### Plotting results\n\nPlotting is done with matplotlib, using the array of loss values\n``plot_losses`` saved while training.\n\n\n","metadata":{"id":"Mmma56Y86Erf"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"id":"n7eKAVeu6Erf","execution":{"iopub.status.busy":"2023-12-10T16:10:49.083628Z","iopub.execute_input":"2023-12-10T16:10:49.083913Z","iopub.status.idle":"2023-12-10T16:10:49.096824Z","shell.execute_reply.started":"2023-12-10T16:10:49.083880Z","shell.execute_reply":"2023-12-10T16:10:49.096035Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Evaluation\n\nEvaluation is mostly the same as training, but there are no targets so\nwe simply feed the decoder's predictions back to itself for each step.\nEvery time it predicts a word we add it to the output string, and if it\npredicts the EOS token we stop there. We also store the decoder's\nattention outputs for display later.\n\n\n","metadata":{"id":"EbfwezRb6Erf"}},{"cell_type":"code","source":"def evaluate(encoder, decoder, sentence, input_lang, output_lang):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, sentence)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn","metadata":{"id":"obs79dIc6Erg","execution":{"iopub.status.busy":"2023-12-10T16:10:49.097900Z","iopub.execute_input":"2023-12-10T16:10:49.098148Z","iopub.status.idle":"2023-12-10T16:10:49.108529Z","shell.execute_reply.started":"2023-12-10T16:10:49.098125Z","shell.execute_reply":"2023-12-10T16:10:49.107612Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"We can evaluate random sentences from the training set and print out the\ninput, target, and output to make some subjective quality judgements:\n\n\n","metadata":{"id":"DwhfhPBr6Erg"}},{"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"id":"bNtYCKlt6Erg","execution":{"iopub.status.busy":"2023-12-10T16:10:49.109433Z","iopub.execute_input":"2023-12-10T16:10:49.109660Z","iopub.status.idle":"2023-12-10T16:10:49.118797Z","shell.execute_reply.started":"2023-12-10T16:10:49.109639Z","shell.execute_reply":"2023-12-10T16:10:49.117940Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"print(len(pairs))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:49.119849Z","iopub.execute_input":"2023-12-10T16:10:49.120100Z","iopub.status.idle":"2023-12-10T16:10:49.129681Z","shell.execute_reply.started":"2023-12-10T16:10:49.120078Z","shell.execute_reply":"2023-12-10T16:10:49.128803Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"135283\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Training and Evaluating\n\nWith all these helper functions in place (it looks like extra work, but\nit makes it easier to run multiple experiments) we can actually\ninitialize a network and start training.\n\nRemember that the input sentences were heavily filtered. For this small\ndataset we can use relatively small networks of 256 hidden nodes and a\nsingle GRU layer. After about 40 minutes on a MacBook CPU we'll get some\nreasonable results.\n\n.. Note::\n   If you run this notebook you can train, interrupt the kernel,\n   evaluate, and continue training later. Comment out the lines where the\n   encoder and decoder are initialized and run ``trainIters`` again.\n\n\n","metadata":{"id":"pqMxsJIG6Erg"}},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 32\n\n\n\ninput_lang, output_lang, train_dataloader, test_dataloader, val_dataloader = get_dataloader(batch_size)\n\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = AttnDecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrain(train_dataloader, encoder, decoder, 20, print_every=1, plot_every=5)","metadata":{"id":"D30x7eXm6Erj","execution":{"iopub.status.busy":"2023-12-10T16:10:49.130702Z","iopub.execute_input":"2023-12-10T16:10:49.130973Z","iopub.status.idle":"2023-12-10T16:56:59.887798Z","shell.execute_reply.started":"2023-12-10T16:10:49.130943Z","shell.execute_reply":"2023-12-10T16:56:59.886383Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 135283 sentence pairs\nCounting words...\nCounted words:\nfra 21170\neng 12917\nlen of training samples  94698\n2m 18s (- 44m 0s) (1 5 1% ) 1.1320\ntraining_loss  1.533872699999326 val_loss_avg  1.1319529556342074  accuracy  0.735\n4m 37s (- 41m 40s) (2 10 1% ) 0.8429\ntraining_loss  1.0121917736087296 val_loss_avg  0.8428726548882755  accuracy  0.825\n6m 55s (- 39m 14s) (3 15 0% ) 0.6806\ntraining_loss  0.7973666756036314 val_loss_avg  0.6805990667459932  accuracy  0.835\n9m 13s (- 36m 55s) (4 20 0% ) 0.5806\ntraining_loss  0.6694069208929667 val_loss_avg  0.5805689741731496  accuracy  0.9\n11m 32s (- 34m 36s) (5 25 0% ) 0.5119\ntraining_loss  0.5843993532597214 val_loss_avg  0.5118590659487087  accuracy  0.905\n13m 50s (- 32m 16s) (6 30 0% ) 0.4617\ntraining_loss  0.5238899617984488 val_loss_avg  0.46167325418744537  accuracy  0.92\n16m 8s (- 29m 58s) (7 35 0% ) 0.4203\ntraining_loss  0.477090929317716 val_loss_avg  0.42033322806394585  accuracy  0.905\n18m 27s (- 27m 40s) (8 40 0% ) 0.3868\ntraining_loss  0.4400490918574301 val_loss_avg  0.38683545359888594  accuracy  0.925\n20m 44s (- 25m 21s) (9 45 0% ) 0.3625\ntraining_loss  0.4087949366535287 val_loss_avg  0.362482646203323  accuracy  0.855\n23m 2s (- 23m 2s) (10 50 0% ) 0.3394\ntraining_loss  0.3834151884037498 val_loss_avg  0.3393530702520464  accuracy  0.925\n25m 20s (- 20m 44s) (11 55 0% ) 0.3220\ntraining_loss  0.3617400398679279 val_loss_avg  0.3219581982825656  accuracy  0.94\n27m 40s (- 18m 26s) (12 60 0% ) 0.3055\ntraining_loss  0.3429574555490871 val_loss_avg  0.30547427253646625  accuracy  0.92\n29m 57s (- 16m 7s) (13 65 0% ) 0.2907\ntraining_loss  0.3270902132816814 val_loss_avg  0.2907209709034981  accuracy  0.945\n32m 14s (- 13m 48s) (14 70 0% ) 0.2811\ntraining_loss  0.31318648970509705 val_loss_avg  0.28109467242013764  accuracy  0.955\n34m 30s (- 11m 30s) (15 75 0% ) 0.2690\ntraining_loss  0.30039959399382005 val_loss_avg  0.26896922143327223  accuracy  0.955\n36m 47s (- 9m 11s) (16 80 0% ) 0.2588\ntraining_loss  0.29005512928942573 val_loss_avg  0.2588495521680326  accuracy  0.945\n39m 4s (- 6m 53s) (17 85 0% ) 0.2502\ntraining_loss  0.2792086020212721 val_loss_avg  0.2502074012784539  accuracy  0.97\n41m 20s (- 4m 35s) (18 90 0% ) 0.2425\ntraining_loss  0.2705105227846149 val_loss_avg  0.24250024329820596  accuracy  0.935\n43m 38s (- 2m 17s) (19 95 0% ) 0.2357\ntraining_loss  0.2629459274907571 val_loss_avg  0.23574159986566048  accuracy  0.955\n45m 54s (- 0m 0s) (20 100 0% ) 0.2306\ntraining_loss  0.25481003899177584 val_loss_avg  0.23059459937031607  accuracy  0.89\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Set dropout layers to ``eval`` mode\n\n","metadata":{"id":"T_GvV-IP6Erj"}},{"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\nevaluateRandomly(encoder, decoder)","metadata":{"id":"aOMAx0tP6Erj","execution":{"iopub.status.busy":"2023-12-10T16:56:59.889956Z","iopub.execute_input":"2023-12-10T16:56:59.890792Z","iopub.status.idle":"2023-12-10T16:57:00.044532Z","shell.execute_reply.started":"2023-12-10T16:56:59.890740Z","shell.execute_reply":"2023-12-10T16:57:00.043645Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"> ils sont similaires\n= they re similar\n< they appreciate motion <EOS>\n\n> mangez vous du riz tous les jours ?\n= do you eat rice every day ?\n< do you eat rice every day ? <EOS>\n\n> je me rappelle lui avoir donne la cle\n= i remember that i gave him the key\n< i remember him the key key the key <EOS>\n\n> papa s assure que toutes les lampes sont deja eteintes avant d aller dormir\n= papa made sure all the lights were turned off before going to bed\n< papa made sure everything the lights are already going to go before they go to sleep <EOS>\n\n> je ne suis pas heureux\n= i m not happy\n< i m not happy <EOS>\n\n> si tu te reposes tu seras bientot de nouveau sur pieds\n= if you rest you will be back on your feet again soon\n< if you rest of you will be back on your new side feet <EOS>\n\n> le medecin de tom lui a dit d arreter de fumer\n= tom s doctor told him to quit smoking\n< the doctor tried to told tom to stop smoking <EOS>\n\n> qu est ce que c est que ce barouf ?\n= what s the commotion ?\n< what s the commotion ? <EOS>\n\n> le navire arborait le pavillon etatsunien\n= the ship was flying the american flag\n< the ship was flying the american flag <EOS>\n\n> pourquoi voulez vous faire cela ?\n= why do you want to do this ?\n< how do you want to do this ? <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(encoder.state_dict(), 'bahdanau_encoder_weights.pth')\ntorch.save(decoder.state_dict(), 'bahdanau_decoder_weights.pth')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:57:00.045705Z","iopub.execute_input":"2023-12-10T16:57:00.045987Z","iopub.status.idle":"2023-12-10T16:57:00.100544Z","shell.execute_reply.started":"2023-12-10T16:57:00.045962Z","shell.execute_reply":"2023-12-10T16:57:00.099767Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"\n\n\n","metadata":{"id":"mVWGE9BZ6Erj"}},{"cell_type":"code","source":"def showAttention(input_sentence, output_words, attentions):\n    fig = plt.figure()\n    ax = fig.add_subplot(111)\n    cax = ax.matshow(attentions.cpu().numpy(), cmap='bone')\n    fig.colorbar(cax)\n\n    # Set up axes\n    ax.set_xticklabels([''] + input_sentence.split(' ') +\n                       ['<EOS>'], rotation=90)\n    ax.set_yticklabels([''] + output_words)\n\n    # Show label at every tick\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n\n    plt.show()\n\n\ndef evaluateAndShowAttention(input_sentence):\n    output_words, attentions = evaluate(encoder, decoder, input_sentence, input_lang, output_lang)\n    print('input =', input_sentence)\n    print('output =', ' '.join(output_words))\n    showAttention(input_sentence, output_words, attentions[0, :len(output_words), :])\n\n\nevaluateAndShowAttention('il n est pas aussi grand que son pere')\n\nevaluateAndShowAttention('je suis trop fatigue pour conduire')\n\nevaluateAndShowAttention('je suis desole si c est une question idiote')\n\nevaluateAndShowAttention('je suis reellement fiere de vous')","metadata":{"id":"pns-4fRC6Erj","execution":{"iopub.status.busy":"2023-12-10T16:57:00.101754Z","iopub.execute_input":"2023-12-10T16:57:00.102101Z","iopub.status.idle":"2023-12-10T16:57:01.031945Z","shell.execute_reply.started":"2023-12-10T16:57:00.102066Z","shell.execute_reply":"2023-12-10T16:57:01.030568Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"input = il n est pas aussi grand que son pere\noutput = he is not as tall as his father his father <EOS>\ninput = je suis trop fatigue pour conduire\noutput = i m too tired to drive driving <EOS>\ninput = je suis desole si c est une question idiote\noutput = i m a stupid question is stupid <EOS>\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_42/1690937169.py:8: UserWarning: FixedFormatter should only be used together with FixedLocator\n  ax.set_xticklabels([''] + input_sentence.split(' ') +\n/tmp/ipykernel_42/1690937169.py:10: UserWarning: FixedFormatter should only be used together with FixedLocator\n  ax.set_yticklabels([''] + output_words)\n","output_type":"stream"},{"name":"stdout","text":"input = je suis reellement fiere de vous\noutput = of stars is proud of you <EOS>\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Exercises\n\n-  Try with a different dataset\n\n   -  Another language pair\n   -  Human → Machine (e.g. IOT commands)\n   -  Chat → Response\n   -  Question → Answer\n\n-  Replace the embeddings with pretrained word embeddings such as ``word2vec`` or\n   ``GloVe``\n-  Try with more layers, more hidden units, and more sentences. Compare\n   the training time and results.\n-  If you use a translation file where pairs have two of the same phrase\n   (``I am test \\t I am test``), you can use this as an autoencoder. Try\n   this:\n\n   -  Train as an autoencoder\n   -  Save only the Encoder network\n   -  Train a new Decoder for translation from there\n\n\n","metadata":{"id":"nWcdy-fr6Erj"}}]}