{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7140029,"sourceType":"datasetVersion","datasetId":4120833}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://download.pytorch.org/tutorial/data.zip\n!unzip data.zip","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:32:51.838580Z","iopub.execute_input":"2023-12-10T07:32:51.838959Z","iopub.status.idle":"2023-12-10T07:33:33.514783Z","shell.execute_reply.started":"2023-12-10T07:32:51.838930Z","shell.execute_reply":"2023-12-10T07:33:33.513317Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"--2023-12-10 07:32:52--  https://download.pytorch.org/tutorial/data.zip\nResolving download.pytorch.org (download.pytorch.org)... 99.86.38.96, 99.86.38.106, 99.86.38.37, ...\nConnecting to download.pytorch.org (download.pytorch.org)|99.86.38.96|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2882130 (2.7M) [application/zip]\nSaving to: ‘data.zip.1’\n\ndata.zip.1          100%[===================>]   2.75M  --.-KB/s    in 0.06s   \n\n2023-12-10 07:32:52 (43.0 MB/s) - ‘data.zip.1’ saved [2882130/2882130]\n\nArchive:  data.zip\nreplace data/eng-fra.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: ^C\n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://www.statmt.org/europarl/v7/fr-en.tgz\n!tar -xf fr-en.tgz","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-12-10T07:33:33.517238Z","iopub.execute_input":"2023-12-10T07:33:33.517612Z","iopub.status.idle":"2023-12-10T07:33:50.625881Z","shell.execute_reply.started":"2023-12-10T07:33:33.517579Z","shell.execute_reply":"2023-12-10T07:33:50.624470Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"--2023-12-10 07:33:34--  https://www.statmt.org/europarl/v7/fr-en.tgz\nResolving www.statmt.org (www.statmt.org)... 129.215.32.28\nConnecting to www.statmt.org (www.statmt.org)|129.215.32.28|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 202718517 (193M) [application/x-gzip]\nSaving to: ‘fr-en.tgz.1’\n\nfr-en.tgz.1         100%[===================>] 193.33M  23.3MB/s    in 9.3s    \n\n2023-12-10 07:33:44 (20.7 MB/s) - ‘fr-en.tgz.1’ saved [202718517/202718517]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:33:50.627363Z","iopub.execute_input":"2023-12-10T07:33:50.627671Z","iopub.status.idle":"2023-12-10T07:34:02.312131Z","shell.execute_reply.started":"2023-12-10T07:33:50.627644Z","shell.execute_reply":"2023-12-10T07:34:02.311130Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport string\nimport random\nimport unicodedata\nimport pickle\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:34:02.314825Z","iopub.execute_input":"2023-12-10T07:34:02.315190Z","iopub.status.idle":"2023-12-10T07:34:02.321453Z","shell.execute_reply.started":"2023-12-10T07:34:02.315158Z","shell.execute_reply":"2023-12-10T07:34:02.320598Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:34:02.322498Z","iopub.execute_input":"2023-12-10T07:34:02.322768Z","iopub.status.idle":"2023-12-10T07:34:02.338255Z","shell.execute_reply.started":"2023-12-10T07:34:02.322745Z","shell.execute_reply":"2023-12-10T07:34:02.337492Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\nimport unicodedata\nimport pickle\nimport pandas as pd \n\n\nfile = open('europarl-v7.fr-en.en', mode='rt', encoding='utf-8')\nt = file.read()\nfile.close()\nsentences = t.strip().split('\\n')\nnew_s = []\n    re_print = re.compile('[^%s]' % re.escape(string.printable))\n    table = str.maketrans('', '', string.punctuation)\n    for s in sentences:\n        s = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n        s = s.decode('UTF-8')\n        s = s.split()\n        s = [w.lower() for w in s]\n        s = [w.translate(table) for w in s]\n        s = [re_print.sub('', w) for w in s]\n        s = [wa for w in s if w.isalpha()]\n        new_s.append(' '.join(s))\npickle.dump(new_s, open(filename, 'wb'))\nprint('Saved: %s' % filename)\nfor i in range(10):\n    print(new_s[i])\n\nfile = open('europarl-v7.fr-en.fr', mode='rt', encoding='utf-8')\nt = file.read()\nfile.close()\nsentences = t.strip().split('\\n')\nnew_s = []\n    re_print = re.compile('[^%s]' % re.escape(string.printable))\n    table = str.maketrans('', '', string.punctuation)\n    for s in sentences:\n        s = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n        s = s.decode('UTF-8')\n        s = s.split()\n        s = [w.lower() for w in s]\n        s = [w.translate(table) for w in s]\n        s = [re_print.sub('', w) for w in s]\n        s = [wa for w in s if w.isalpha()]\n        new_s.append(' '.join(s))\npickle.dump(new_s, open(filename, 'wb'))\nprint('Saved: %s' % filename)\nfor i in range(1):\n    print(new_s[i])\n\nwith open('french.pkl', 'rb') as f:\n    fr = pickle.load(f)\n\nwith open('english.pkl', 'rb') as f:\n    eng = pickle.load(f)\n    \ndata = pd.DataFrame(zip(eng, fr), columns = ['English', 'French'])\ndata","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:34:02.339389Z","iopub.execute_input":"2023-12-10T07:34:02.339668Z","iopub.status.idle":"2023-12-10T07:36:38.687366Z","shell.execute_reply.started":"2023-12-10T07:34:02.339645Z","shell.execute_reply":"2023-12-10T07:36:38.686407Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Saved: english.pkl\nresumption of the session\ni declare resumed the session of the european parliament adjourned on friday december and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\nalthough as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\nyou have requested a debate on this subject in the course of the next few days during this partsession\nin the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\nplease rise then for this minute s silence\nthe house rose and observed a minute s silence\nmadam president on a point of order\nyou will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\none of the people assassinated very recently in sri lanka was mr kumar ponnambalam who had visited the european parliament just a few months ago\nSaved: french.pkl\nreprise de la session\n","output_type":"stream"},{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2007718  i would also like although they are absent to ...   \n2007719  i am not going to reopen the millennium or not...   \n2007720                         adjournment of the session   \n2007721  i declare the session of the european parliame...   \n2007722                       the sitting was closed at am   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2007718  je me permettrai meme bien quils soient absent...  \n2007719  je ne rouvrirai pas le debat sur le millenaire...  \n2007720                         interruption de la session  \n2007721  je declare interrompue la session du parlement...  \n2007722                              la seance est levee a  \n\n[2007723 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2007718</th>\n      <td>i would also like although they are absent to ...</td>\n      <td>je me permettrai meme bien quils soient absent...</td>\n    </tr>\n    <tr>\n      <th>2007719</th>\n      <td>i am not going to reopen the millennium or not...</td>\n      <td>je ne rouvrirai pas le debat sur le millenaire...</td>\n    </tr>\n    <tr>\n      <th>2007720</th>\n      <td>adjournment of the session</td>\n      <td>interruption de la session</td>\n    </tr>\n    <tr>\n      <th>2007721</th>\n      <td>i declare the session of the european parliame...</td>\n      <td>je declare interrompue la session du parlement...</td>\n    </tr>\n    <tr>\n      <th>2007722</th>\n      <td>the sitting was closed at am</td>\n      <td>la seance est levee a</td>\n    </tr>\n  </tbody>\n</table>\n<p>2007723 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data2 = pd.read_csv('./data/eng-fra.txt', delimiter='\\t', names = ['English', 'French'])\ndata2","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:36:38.688613Z","iopub.execute_input":"2023-12-10T07:36:38.688905Z","iopub.status.idle":"2023-12-10T07:36:38.903003Z","shell.execute_reply.started":"2023-12-10T07:36:38.688881Z","shell.execute_reply":"2023-12-10T07:36:38.902105Z"},"trusted":true},"execution_count":34,"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"                                                  English  \\\n0                                                     Go.   \n1                                                    Run!   \n2                                                    Run!   \n3                                                    Wow!   \n4                                                   Fire!   \n...                                                   ...   \n135837  A carbon footprint is the amount of carbon dio...   \n135838  Death is something that we're often discourage...   \n135839  Since there are usually multiple websites on a...   \n135840  If someone who doesn't know your background sa...   \n135841  It may be impossible to get a completely error...   \n\n                                                   French  \n0                                                    Va !  \n1                                                 Cours !  \n2                                                Courez !  \n3                                              Ça alors !  \n4                                                Au feu !  \n...                                                   ...  \n135837  Une empreinte carbone est la somme de pollutio...  \n135838  La mort est une chose qu'on nous décourage sou...  \n135839  Puisqu'il y a de multiples sites web sur chaqu...  \n135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n135841  Il est peut-être impossible d'obtenir un Corpu...  \n\n[135842 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Va !</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135837</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>135838</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>135839</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>135840</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>135841</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>135842 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([data,data2], ignore_index= True, axis = 0)\n\ndata.to_csv('eng-fra.txt')\ndata","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:36:38.904016Z","iopub.execute_input":"2023-12-10T07:36:38.904284Z","iopub.status.idle":"2023-12-10T07:37:10.797262Z","shell.execute_reply.started":"2023-12-10T07:36:38.904263Z","shell.execute_reply":"2023-12-10T07:37:10.796388Z"},"trusted":true},"execution_count":35,"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2143560  A carbon footprint is the amount of carbon dio...   \n2143561  Death is something that we're often discourage...   \n2143562  Since there are usually multiple websites on a...   \n2143563  If someone who doesn't know your background sa...   \n2143564  It may be impossible to get a completely error...   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2143560  Une empreinte carbone est la somme de pollutio...  \n2143561  La mort est une chose qu'on nous décourage sou...  \n2143562  Puisqu'il y a de multiples sites web sur chaqu...  \n2143563  Si quelqu'un qui ne connaît pas vos antécédent...  \n2143564  Il est peut-être impossible d'obtenir un Corpu...  \n\n[2143565 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2143560</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>2143561</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>2143562</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>2143563</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>2143564</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2143565 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport torchtext\nfrom torchtext.data import get_tokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:10.798257Z","iopub.execute_input":"2023-12-10T07:37:10.798518Z","iopub.status.idle":"2023-12-10T07:37:10.804227Z","shell.execute_reply.started":"2023-12-10T07:37:10.798496Z","shell.execute_reply":"2023-12-10T07:37:10.803375Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\nclass Voc:\n    def __init__(self, name):\n        self.name = name\n        self.w2i = {}\n        self.w2c = {}\n        self.i2w = {0: \"SOS\", 1: \"EOS\"}\n        self.num_of_W = 2 \n\n    def insertSeq(self, seq):\n        for word in seq.split(' '):\n            self.insertWord(word)\n\n    def insertWord(self, word):\n        if word not in self.w2i:\n            self.w2i[word] = self.num_of_W\n            self.w2c[word] = 1\n            self.i2w[self.num_of_W] = word\n            self.num_of_W += 1\n        else:\n            self.w2c[word] += 1","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:10.807898Z","iopub.execute_input":"2023-12-10T07:37:10.808203Z","iopub.status.idle":"2023-12-10T07:37:10.818004Z","shell.execute_reply.started":"2023-12-10T07:37:10.808180Z","shell.execute_reply":"2023-12-10T07:37:10.817141Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"def removeNonLettersAndLowercase(s):\n    s = ''.join(c for c in unicodedata.normalize('NFD', s.lower().strip()) if unicodedata.category(c) != 'Mn')\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n    return s.strip()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:10.819193Z","iopub.execute_input":"2023-12-10T07:37:10.819790Z","iopub.status.idle":"2023-12-10T07:37:10.829177Z","shell.execute_reply.started":"2023-12-10T07:37:10.819758Z","shell.execute_reply":"2023-12-10T07:37:10.828397Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"def rVocs(Voc1, Voc2, reverse=False):\n    print(\"Reading lines...\")\n\n    lines = open('data/%s-%s.txt' % (Voc1, Voc2), encoding='utf-8').read().strip().split('\\n')\n    pairs = [[removeNonLettersAndLowercase(s) for s in l.split('\\t')] for l in lines]\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        i_Voc = Voc(Voc2)\n        o_Voc = Voc(Voc1)\n    else:\n        i_Voc = Voc(Voc1)\n        o_Voc = Voc(Voc2)\n\n    return i_Voc, o_Voc, pairs","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:10.832267Z","iopub.execute_input":"2023-12-10T07:37:10.832537Z","iopub.status.idle":"2023-12-10T07:37:10.844003Z","shell.execute_reply.started":"2023-12-10T07:37:10.832515Z","shell.execute_reply":"2023-12-10T07:37:10.843148Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"def processData(Voc1, Voc2, reverse=False):\n    i_Voc, o_Voc, pairs = rVocs(Voc1, Voc2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        i_Voc.insertSeq(pair[0])\n        o_Voc.insertSeq(pair[1])\n    print(i_Voc.name, i_Voc.num_of_W)\n    print(o_Voc.name, o_Voc.num_of_W)\n    return i_Voc, o_Voc, pairs\n\ni_Voc, o_Voc, pairs = processData('eng', 'fra', True)\nprint(random.choice(pairs))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:10.860713Z","iopub.execute_input":"2023-12-10T07:37:10.861022Z","iopub.status.idle":"2023-12-10T07:37:18.995076Z","shell.execute_reply.started":"2023-12-10T07:37:10.860998Z","shell.execute_reply":"2023-12-10T07:37:18.994047Z"},"trusted":true},"execution_count":41,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 122295 sentence pairs\nCounting words...\nCounted words:\nfra 19507\neng 11759\n['l ai je blesse ?', 'did i hurt his feelings ?']\n","output_type":"stream"}]},{"cell_type":"code","source":"MAX_LENGTH = 20","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, i_s, h_s, dropout_p=0.1):\n        super(Encoder, self).__init__()\n        self.h_s = h_s\n        self.embedding = nn.Embedding(i_s, h_s)\n        self.gru = nn.GRU(h_s, h_s, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        o, hidden = self.gru(embedded)\n        return o, hidden","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:18.996193Z","iopub.execute_input":"2023-12-10T07:37:18.996463Z","iopub.status.idle":"2023-12-10T07:37:19.003077Z","shell.execute_reply.started":"2023-12-10T07:37:18.996440Z","shell.execute_reply":"2023-12-10T07:37:19.002079Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, h_s, o_s):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(o_s, h_s)\n        self.gru = nn.GRU(h_s, h_s, batch_first=True)\n        self.out = nn.Linear(h_s, o_s)\n\n    def forward(self, e_o, e_h, t_t=None):\n        batch_size = e_o.size(0)\n        d_i = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        d_h = e_h\n        d_os = []\n\n        for i in range(MAX_LENGTH):\n            d_o, d_h  = self.forward(d_i, d_h)\n            d_os.append(d_o)\n\n            if t_t is not None:\n                d_i = t_t[:, i].unsqueeze(1)\n            else:\n                _, topi = d_o.topk(1)\n                d_i = topi.squeeze(-1).detach()  \n\n        d_os = torch.cat(d_os, dim=1)\n        d_os = F.log_softmax(d_os, dim=-1)\n        return d_os, d_h, None\n\n    def forward(self, input, hidden):\n        o = self.embedding(input)\n        o = F.relu(o)\n        o, hidden = self.gru(o, hidden)\n        o = self.out(o)\n        return o, hidden","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.004361Z","iopub.execute_input":"2023-12-10T07:37:19.004661Z","iopub.status.idle":"2023-12-10T07:37:19.021748Z","shell.execute_reply.started":"2023-12-10T07:37:19.004628Z","shell.execute_reply":"2023-12-10T07:37:19.020806Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef i_f_s(Voc, sentence):\n    return [Voc.w2i[word] for word in sentence.split(' ')]\n\ndef t_f_s(Voc, sentence):\n    indexes = i_f_s(Voc, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef t_f_p(pair):\n    i_t = t_f_s(i_Voc, pair[0])\n    t_t = t_f_s(o_Voc, pair[1])\n    return (i_t, t_t)\n\ndef get_data(batch_size):\n    i_Voc, o_Voc, pairs = processData('eng', 'fra', True)\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = i_f_s(i_Voc, inp)\n        tgt_ids = i_f_s(o_Voc, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n    \n    train_pairs, test_pairs = train_test_split(train_data, test_size=0.3, random_state=42)\n    val_pairs, test_pairs = train_test_split(test_pairs, test_size=0.5, random_state=42)\n    print('len of training samples ', len(train_pairs))\n\n    \n    train_dataloader = DataLoader(train_pairs, batch_size=batch_size, shuffle= True)\n    test_dataloader = DataLoader(test_pairs, batch_size=batch_size, shuffle= True)\n    val_dataloader = DataLoader(val_pairs, batch_size=batch_size, shuffle= True)                                        \n    return i_Voc, o_Voc, train_dataloader, test_dataloader, val_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.023226Z","iopub.execute_input":"2023-12-10T07:37:19.023853Z","iopub.status.idle":"2023-12-10T07:37:19.037185Z","shell.execute_reply.started":"2023-12-10T07:37:19.023827Z","shell.execute_reply":"2023-12-10T07:37:19.036333Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.038505Z","iopub.execute_input":"2023-12-10T07:37:19.038766Z","iopub.status.idle":"2023-12-10T07:37:19.051599Z","shell.execute_reply.started":"2023-12-10T07:37:19.038735Z","shell.execute_reply":"2023-12-10T07:37:19.050420Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    for data in dataloader:\n        i_t, t_t = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        e_o, e_h = encoder(i_t)\n        d_os, _, _ = decoder(e_o, e_h, t_t)\n        \n        _, predicted = d_os.max(dim=2)\n        correct = (predicted == t_t)\n        accuracy = correct.sum().item() / (t_t.size(0) * t_t.size(1))\n\n        loss = criterion(\n            d_os.view(-1, d_os.size(-1)),\n            t_t.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader), accuracy","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.052801Z","iopub.execute_input":"2023-12-10T07:37:19.053205Z","iopub.status.idle":"2023-12-10T07:37:19.066353Z","shell.execute_reply.started":"2023-12-10T07:37:19.053179Z","shell.execute_reply":"2023-12-10T07:37:19.065400Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"def evaluate_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    #encoder.eval()\n    #decoder.eval()\n    for data in dataloader:\n        i_t, t_t = data\n\n        \n        e_o, e_h = encoder(i_t)\n        d_os, _, _ = decoder(e_o, e_h, t_t)\n\n        loss = criterion(\n            d_os.view(-1, d_os.size(-1)),\n            t_t.view(-1)\n        )\n\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.067900Z","iopub.execute_input":"2023-12-10T07:37:19.068254Z","iopub.status.idle":"2023-12-10T07:37:19.076788Z","shell.execute_reply.started":"2023-12-10T07:37:19.068221Z","shell.execute_reply":"2023-12-10T07:37:19.075989Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.078246Z","iopub.execute_input":"2023-12-10T07:37:19.078568Z","iopub.status.idle":"2023-12-10T07:37:19.088442Z","shell.execute_reply.started":"2023-12-10T07:37:19.078538Z","shell.execute_reply":"2023-12-10T07:37:19.087603Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.090785Z","iopub.execute_input":"2023-12-10T07:37:19.091108Z","iopub.status.idle":"2023-12-10T07:37:19.101767Z","shell.execute_reply.started":"2023-12-10T07:37:19.091076Z","shell.execute_reply":"2023-12-10T07:37:19.100796Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100):\n    start = time.time()\n    plot_losses = []\n    plt_val_losses = []\n    accuracies = []\n    print_loss_total = 0  # Reset every print_every\n    plot_loss_total = 0  # Reset every plot_every\n    plt_val_loss = 0\n    print_val_loss_total = 0\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        val_loss = evaluate_epoch(val_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        print_val_loss_total += val_loss\n        plot_loss_total += loss\n\n        if epoch % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            val_loss_avg = print_val_loss_total / print_every\n            print_loss_total = 0\n            print_val_loss_total = 0\n            print('%s (%d %d %d%% ) %.4f' % (timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, print_loss_avg, val_loss_avg))\n            print('training_loss ', print_loss_avg, 'val_loss_avg ', val_loss_avg, ' accuracy ', accuracy)\n\n        if epoch % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plt_val_avg = print_val_loss_total / plot_every\n            plt_val_losses.append(plt_val_avg)\n            accuracies.append(accuracy)\n            plot_loss_total = 0\n            print_val_loss_total = 0\n\n    showPlot(plot_losses)\n    showPlot(plt_val_losses)\n    showPlot(accuracies)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.103204Z","iopub.execute_input":"2023-12-10T07:37:19.103541Z","iopub.status.idle":"2023-12-10T07:37:19.115391Z","shell.execute_reply.started":"2023-12-10T07:37:19.103517Z","shell.execute_reply":"2023-12-10T07:37:19.114492Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder, decoder, sentence, i_Voc, o_Voc):\n    with torch.no_grad():\n        i_t = t_f_s(i_Voc, sentence)\n\n        e_o, e_h = encoder(i_t)\n        d_os, d_h, decoder_attn = decoder(e_o, e_h)\n\n        _, topi = d_os.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(o_Voc.i2w[idx.item()])\n    return decoded_words, decoder_attn","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.116663Z","iopub.execute_input":"2023-12-10T07:37:19.125298Z","iopub.status.idle":"2023-12-10T07:37:19.134745Z","shell.execute_reply.started":"2023-12-10T07:37:19.125265Z","shell.execute_reply":"2023-12-10T07:37:19.133842Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.135887Z","iopub.execute_input":"2023-12-10T07:37:19.136289Z","iopub.status.idle":"2023-12-10T07:37:19.148600Z","shell.execute_reply.started":"2023-12-10T07:37:19.136258Z","shell.execute_reply":"2023-12-10T07:37:19.147727Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\n\n\ni_Voc, o_Voc, train_dataloader, test_pairs, val_dataloader = get_data(batch_size)\ntest_dataloader = DataLoader(test_pairs, batch_size=batch_size, shuffle= True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:19.150252Z","iopub.execute_input":"2023-12-10T07:37:19.150631Z","iopub.status.idle":"2023-12-10T07:37:29.525923Z","shell.execute_reply.started":"2023-12-10T07:37:19.150601Z","shell.execute_reply":"2023-12-10T07:37:29.524900Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 122295 sentence pairs\nCounting words...\nCounted words:\nfra 19507\neng 11759\nlen of training samples  85606\n","output_type":"stream"}]},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 32\n\n\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrain(train_dataloader, val_dataloader, encoder, decoder, 55, print_every=1, plot_every=5)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T07:37:29.527179Z","iopub.execute_input":"2023-12-10T07:37:29.527466Z","iopub.status.idle":"2023-12-10T08:08:27.529051Z","shell.execute_reply.started":"2023-12-10T07:37:29.527441Z","shell.execute_reply":"2023-12-10T08:08:27.527728Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 122295 sentence pairs\nCounting words...\nCounted words:\nfra 19507\neng 11759\nlen of training samples  85606\n0m 33s (- 30m 17s) (1 1 2% ) 1.8611\ntraining_loss  2.351235716822258 val_loss_avg  1.8611323085811495  accuracy  0.7361111111111112\n1m 7s (- 29m 43s) (2 3 1% ) 1.5900\ntraining_loss  1.661166935000897 val_loss_avg  1.5899922833210085  accuracy  0.8055555555555556\n1m 40s (- 29m 7s) (3 5 1% ) 1.4467\ntraining_loss  1.4026831124529175 val_loss_avg  1.4466606688001014  accuracy  0.7638888888888888\n2m 14s (- 28m 31s) (4 7 1% ) 1.3535\ntraining_loss  1.2313220499832356 val_loss_avg  1.3534981060111149  accuracy  0.6527777777777778\n2m 47s (- 27m 58s) (5 9 1% ) 1.2947\ntraining_loss  1.1049468882593516 val_loss_avg  1.2946840600477278  accuracy  0.8333333333333334\n3m 21s (- 27m 24s) (6 10 1% ) 1.2523\ntraining_loss  1.006548213450898 val_loss_avg  1.2523192634565905  accuracy  0.7777777777777778\n3m 55s (- 26m 51s) (7 12 0% ) 1.2214\ntraining_loss  0.9258391585852533 val_loss_avg  1.2214061966756495  accuracy  0.8055555555555556\n4m 28s (- 26m 18s) (8 14 0% ) 1.1972\ntraining_loss  0.8585124977812817 val_loss_avg  1.1971537783378507  accuracy  0.9166666666666666\n5m 2s (- 25m 45s) (9 16 0% ) 1.1796\ntraining_loss  0.8015517665154018 val_loss_avg  1.1796361081276205  accuracy  0.75\n5m 35s (- 25m 11s) (10 18 0% ) 1.1643\ntraining_loss  0.7523954793788571 val_loss_avg  1.1642573296193046  accuracy  0.8888888888888888\n6m 9s (- 24m 37s) (11 20 0% ) 1.1496\ntraining_loss  0.7100447026848437 val_loss_avg  1.1495765989665785  accuracy  0.8611111111111112\n6m 42s (- 24m 4s) (12 21 0% ) 1.1447\ntraining_loss  0.672498511158832 val_loss_avg  1.1446770104589363  accuracy  0.8055555555555556\n7m 16s (- 23m 30s) (13 23 0% ) 1.1363\ntraining_loss  0.6392447675490593 val_loss_avg  1.1363260260027044  accuracy  0.8055555555555556\n7m 50s (- 22m 57s) (14 25 0% ) 1.1339\ntraining_loss  0.6101571879557074 val_loss_avg  1.1339218973698102  accuracy  0.75\n8m 23s (- 22m 23s) (15 27 0% ) 1.1282\ntraining_loss  0.5848301453307071 val_loss_avg  1.1281532288013019  accuracy  0.875\n8m 57s (- 21m 50s) (16 29 0% ) 1.1308\ntraining_loss  0.5608451156494151 val_loss_avg  1.130790950113888  accuracy  0.8055555555555556\n9m 31s (- 21m 16s) (17 30 0% ) 1.1283\ntraining_loss  0.5399312458052585 val_loss_avg  1.1283060705827919  accuracy  0.8472222222222222\n10m 4s (- 20m 43s) (18 32 0% ) 1.1291\ntraining_loss  0.5203372416029418 val_loss_avg  1.1290900675054212  accuracy  0.8888888888888888\n10m 38s (- 20m 9s) (19 34 0% ) 1.1311\ntraining_loss  0.5025834902308002 val_loss_avg  1.1310716749068337  accuracy  0.8888888888888888\n11m 11s (- 19m 35s) (20 36 0% ) 1.1309\ntraining_loss  0.4864123747231625 val_loss_avg  1.130926492529879  accuracy  0.9166666666666666\n11m 45s (- 19m 1s) (21 38 0% ) 1.1321\ntraining_loss  0.47187906081032327 val_loss_avg  1.1321361600729647  accuracy  0.9027777777777778\n12m 18s (- 18m 28s) (22 40 0% ) 1.1356\ntraining_loss  0.4573234582127744 val_loss_avg  1.1355918937651537  accuracy  0.8888888888888888\n12m 52s (- 17m 54s) (23 41 0% ) 1.1393\ntraining_loss  0.4448399793507005 val_loss_avg  1.13926535616353  accuracy  0.8472222222222222\n13m 25s (- 17m 21s) (24 43 0% ) 1.1435\ntraining_loss  0.4322344857492165 val_loss_avg  1.1435385991264304  accuracy  0.9027777777777778\n13m 59s (- 16m 47s) (25 45 0% ) 1.1457\ntraining_loss  0.4208893100877247 val_loss_avg  1.1457318356228208  accuracy  0.9583333333333334\n14m 33s (- 16m 14s) (26 47 0% ) 1.1513\ntraining_loss  0.41112363461533113 val_loss_avg  1.151303504921418  accuracy  0.9583333333333334\n15m 6s (- 15m 40s) (27 49 0% ) 1.1536\ntraining_loss  0.40141236152282744 val_loss_avg  1.1536155577736034  accuracy  0.8055555555555556\n15m 40s (- 15m 6s) (28 50 0% ) 1.1554\ntraining_loss  0.39245040956968147 val_loss_avg  1.155439614522748  accuracy  0.8194444444444444\n16m 14s (- 14m 33s) (29 52 0% ) 1.1606\ntraining_loss  0.3835340795818555 val_loss_avg  1.160554068117607  accuracy  0.8333333333333334\n16m 47s (- 13m 59s) (30 54 0% ) 1.1662\ntraining_loss  0.3754880653446476 val_loss_avg  1.1662340568125455  accuracy  0.9027777777777778\n17m 21s (- 13m 26s) (31 56 0% ) 1.1738\ntraining_loss  0.3674711036051781 val_loss_avg  1.1737687347346482  accuracy  0.8888888888888888\n17m 55s (- 12m 52s) (32 58 0% ) 1.1729\ntraining_loss  0.36029325790914896 val_loss_avg  1.1729155098727355  accuracy  0.8888888888888888\n18m 28s (- 12m 18s) (33 60 0% ) 1.1781\ntraining_loss  0.3535063705269264 val_loss_avg  1.1781016031624132  accuracy  0.9444444444444444\n19m 2s (- 11m 45s) (34 61 0% ) 1.1833\ntraining_loss  0.3463914492773101 val_loss_avg  1.1833337027229083  accuracy  0.9444444444444444\n19m 35s (- 11m 11s) (35 63 0% ) 1.1875\ntraining_loss  0.34033287505887905 val_loss_avg  1.1875209308875148  accuracy  0.9027777777777778\n20m 9s (- 10m 38s) (36 65 0% ) 1.1979\ntraining_loss  0.3340447922981997 val_loss_avg  1.197904406524286  accuracy  0.8888888888888888\n20m 42s (- 10m 4s) (37 67 0% ) 1.1990\ntraining_loss  0.3277380937997179 val_loss_avg  1.19902939113175  accuracy  0.875\n21m 16s (- 9m 30s) (38 69 0% ) 1.1975\ntraining_loss  0.32395858614968615 val_loss_avg  1.1975185744438437  accuracy  0.7916666666666666\n21m 49s (- 8m 57s) (39 70 0% ) 1.2140\ntraining_loss  0.3181404975787228 val_loss_avg  1.2139629285509994  accuracy  0.8472222222222222\n22m 23s (- 8m 23s) (40 72 0% ) 1.2120\ntraining_loss  0.31296084059460816 val_loss_avg  1.2119754017022428  accuracy  0.8888888888888888\n22m 56s (- 7m 50s) (41 74 0% ) 1.2176\ntraining_loss  0.3080603090158047 val_loss_avg  1.2175723993404401  accuracy  0.9583333333333334\n23m 30s (- 7m 16s) (42 76 0% ) 1.2194\ntraining_loss  0.3032370352051228 val_loss_avg  1.2193579998788933  accuracy  0.9722222222222222\n24m 4s (- 6m 43s) (43 78 0% ) 1.2231\ntraining_loss  0.2994826427244641 val_loss_avg  1.2231027067019133  accuracy  0.8472222222222222\n24m 37s (- 6m 9s) (44 80 0% ) 1.2269\ntraining_loss  0.2946527441309261 val_loss_avg  1.2269434374903136  accuracy  0.9444444444444444\n25m 11s (- 5m 35s) (45 81 0% ) 1.2361\ntraining_loss  0.2899372942400442 val_loss_avg  1.2361427247524261  accuracy  0.8888888888888888\n25m 45s (- 5m 2s) (46 83 0% ) 1.2365\ntraining_loss  0.28728183464708174 val_loss_avg  1.236466324910885  accuracy  0.9166666666666666\n26m 18s (- 4m 28s) (47 85 0% ) 1.2460\ntraining_loss  0.2836793609331007 val_loss_avg  1.2460154061325752  accuracy  0.9583333333333334\n26m 52s (- 3m 55s) (48 87 0% ) 1.2464\ntraining_loss  0.28039646062092305 val_loss_avg  1.2463593968946345  accuracy  0.8333333333333334\n27m 25s (- 3m 21s) (49 89 0% ) 1.2554\ntraining_loss  0.27625231449568843 val_loss_avg  1.2553582586062495  accuracy  0.9444444444444444\n27m 58s (- 2m 47s) (50 90 0% ) 1.2561\ntraining_loss  0.272510937110191 val_loss_avg  1.2561386950340006  accuracy  0.8888888888888888\n28m 32s (- 2m 14s) (51 92 0% ) 1.2615\ntraining_loss  0.26955860150457317 val_loss_avg  1.2614991116606815  accuracy  0.9444444444444444\n29m 5s (- 1m 40s) (52 94 0% ) 1.2703\ntraining_loss  0.2666717953311756 val_loss_avg  1.2703211363599691  accuracy  0.8333333333333334\n29m 39s (- 1m 7s) (53 96 0% ) 1.2769\ntraining_loss  0.2628068785323735 val_loss_avg  1.276912631265793  accuracy  0.8888888888888888\n30m 13s (- 0m 33s) (54 98 0% ) 1.2809\ntraining_loss  0.2605921598332301 val_loss_avg  1.2809354916266864  accuracy  0.9583333333333334\n30m 47s (- 0m 0s) (55 100 0% ) 1.2811\ntraining_loss  0.2568612588744928 val_loss_avg  1.281137929353149  accuracy  0.9166666666666666\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\nevaluateRandomly(encoder, decoder)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:08:27.538474Z","iopub.execute_input":"2023-12-10T08:08:27.539424Z","iopub.status.idle":"2023-12-10T08:08:27.627293Z","shell.execute_reply.started":"2023-12-10T08:08:27.539374Z","shell.execute_reply":"2023-12-10T08:08:27.626369Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"> emploie ceci !\n= use this\n< stop what this is on top of this <EOS>\n\n> j expliquerai tout plus tard\n= i ll explain it all later\n< i wish i might come in later <EOS>\n\n> elle a contracte un rhume la nuit derniere\n= she caught a cold last night\n< she caught a cold last night on the cold <EOS>\n\n> pourrais tu brievement te presenter ?\n= could you please briefly introduce yourself ?\n< could you please briefly introduce along with her progress ? <EOS>\n\n> je suis toujours ton amie\n= i m still your friend\n< i m still your friend s younger brother <EOS>\n\n> j espere etre de retour lundi prochain\n= i expect to be back next monday\n< i hope i will be back next monday <EOS>\n\n> ce fut tres bon\n= that was very good\n< it was very good at me <EOS>\n\n> il s agit d une location\n= it s a rental\n< it s a rental <EOS>\n\n> il s est foule la cheville\n= he sprained his ankle\n< he acted in the sight of his memory <EOS>\n\n> quelle est ta destination ?\n= what is your destination ?\n< what is your destination intersection ? <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(encoder.state_dict(), 'encoder_weights.pth')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:08:27.628333Z","iopub.execute_input":"2023-12-10T08:08:27.628594Z","iopub.status.idle":"2023-12-10T08:08:27.649684Z","shell.execute_reply.started":"2023-12-10T08:08:27.628571Z","shell.execute_reply":"2023-12-10T08:08:27.648724Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"torch.save(decoder.state_dict(), 'decoder_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T08:08:27.651029Z","iopub.execute_input":"2023-12-10T08:08:27.651657Z","iopub.status.idle":"2023-12-10T08:08:27.680161Z","shell.execute_reply.started":"2023-12-10T08:08:27.651623Z","shell.execute_reply":"2023-12-10T08:08:27.679393Z"},"trusted":true},"execution_count":57,"outputs":[]}]}