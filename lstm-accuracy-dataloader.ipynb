{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7140029,"sourceType":"datasetVersion","datasetId":4120833}],"dockerImageVersionId":30588,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!wget https://download.pytorch.org/tutorial/data.zip\n!unzip data.zip","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:06:23.727978Z","iopub.execute_input":"2023-12-10T16:06:23.728831Z","iopub.status.idle":"2023-12-10T16:06:28.090997Z","shell.execute_reply.started":"2023-12-10T16:06:23.728797Z","shell.execute_reply":"2023-12-10T16:06:28.089744Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"--2023-12-10 16:06:24--  https://download.pytorch.org/tutorial/data.zip\nResolving download.pytorch.org (download.pytorch.org)... 13.224.181.60, 13.224.181.95, 13.224.181.117, ...\nConnecting to download.pytorch.org (download.pytorch.org)|13.224.181.60|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2882130 (2.7M) [application/zip]\nSaving to: ‘data.zip’\n\ndata.zip            100%[===================>]   2.75M  2.00MB/s    in 1.4s    \n\n2023-12-10 16:06:26 (2.00 MB/s) - ‘data.zip’ saved [2882130/2882130]\n\nArchive:  data.zip\n   creating: data/\n  inflating: data/eng-fra.txt        \n   creating: data/names/\n  inflating: data/names/Arabic.txt   \n  inflating: data/names/Chinese.txt  \n  inflating: data/names/Czech.txt    \n  inflating: data/names/Dutch.txt    \n  inflating: data/names/English.txt  \n  inflating: data/names/French.txt   \n  inflating: data/names/German.txt   \n  inflating: data/names/Greek.txt    \n  inflating: data/names/Irish.txt    \n  inflating: data/names/Italian.txt  \n  inflating: data/names/Japanese.txt  \n  inflating: data/names/Korean.txt   \n  inflating: data/names/Polish.txt   \n  inflating: data/names/Portuguese.txt  \n  inflating: data/names/Russian.txt  \n  inflating: data/names/Scottish.txt  \n  inflating: data/names/Spanish.txt  \n  inflating: data/names/Vietnamese.txt  \n","output_type":"stream"}]},{"cell_type":"code","source":"!wget https://www.statmt.org/europarl/v7/fr-en.tgz\n!tar -xf fr-en.tgz","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-12-10T16:06:28.097862Z","iopub.execute_input":"2023-12-10T16:06:28.098674Z","iopub.status.idle":"2023-12-10T16:06:54.292887Z","shell.execute_reply.started":"2023-12-10T16:06:28.098610Z","shell.execute_reply":"2023-12-10T16:06:54.291719Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"--2023-12-10 16:06:28--  https://www.statmt.org/europarl/v7/fr-en.tgz\nResolving www.statmt.org (www.statmt.org)... 129.215.32.28\nConnecting to www.statmt.org (www.statmt.org)|129.215.32.28|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 202718517 (193M) [application/x-gzip]\nSaving to: ‘fr-en.tgz’\n\nfr-en.tgz           100%[===================>] 193.33M  12.2MB/s    in 18s     \n\n2023-12-10 16:06:48 (10.7 MB/s) - ‘fr-en.tgz’ saved [202718517/202718517]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:06:54.294333Z","iopub.execute_input":"2023-12-10T16:06:54.294624Z","iopub.status.idle":"2023-12-10T16:07:07.361362Z","shell.execute_reply.started":"2023-12-10T16:06:54.294599Z","shell.execute_reply":"2023-12-10T16:07:07.360305Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport re\nimport string\nimport random\nimport unicodedata\nimport pickle\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport numpy as np\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:07:07.362810Z","iopub.execute_input":"2023-12-10T16:07:07.363109Z","iopub.status.idle":"2023-12-10T16:07:08.856095Z","shell.execute_reply.started":"2023-12-10T16:07:07.363084Z","shell.execute_reply":"2023-12-10T16:07:08.855249Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:07:08.859053Z","iopub.execute_input":"2023-12-10T16:07:08.859789Z","iopub.status.idle":"2023-12-10T16:07:08.884757Z","shell.execute_reply.started":"2023-12-10T16:07:08.859752Z","shell.execute_reply":"2023-12-10T16:07:08.883877Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import re\nimport string\nimport unicodedata\nimport pickle\nimport pandas as pd \n\n\nfile = open('europarl-v7.fr-en.en', mode='rt', encoding='utf-8')\nt = file.read()\nfile.close()\nsentences = t.strip().split('\\n')\nnew_s = []\n    re_print = re.compile('[^%s]' % re.escape(string.printable))\n    table = str.maketrans('', '', string.punctuation)\n    for s in sentences:\n        s = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n        s = s.decode('UTF-8')\n        s = s.split()\n        s = [w.lower() for w in s]\n        s = [w.translate(table) for w in s]\n        s = [re_print.sub('', w) for w in s]\n        s = [wa for w in s if w.isalpha()]\n        new_s.append(' '.join(s))\npickle.dump(new_s, open(filename, 'wb'))\nprint('Saved: %s' % filename)\nfor i in range(10):\n    print(new_s[i])\n\nfile = open('europarl-v7.fr-en.fr', mode='rt', encoding='utf-8')\nt = file.read()\nfile.close()\nsentences = t.strip().split('\\n')\nnew_s = []\n    re_print = re.compile('[^%s]' % re.escape(string.printable))\n    table = str.maketrans('', '', string.punctuation)\n    for s in sentences:\n        s = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n        s = s.decode('UTF-8')\n        s = s.split()\n        s = [w.lower() for w in s]\n        s = [w.translate(table) for w in s]\n        s = [re_print.sub('', w) for w in s]\n        s = [wa for w in s if w.isalpha()]\n        new_s.append(' '.join(s))\npickle.dump(new_s, open(filename, 'wb'))\nprint('Saved: %s' % filename)\nfor i in range(1):\n    print(new_s[i])\n\nwith open('french.pkl', 'rb') as f:\n    fr = pickle.load(f)\n\nwith open('english.pkl', 'rb') as f:\n    eng = pickle.load(f)\n    \ndata = pd.DataFrame(zip(eng, fr), columns = ['English', 'French'])\ndata","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:07:08.885941Z","iopub.execute_input":"2023-12-10T16:07:08.886224Z","iopub.status.idle":"2023-12-10T16:09:47.926737Z","shell.execute_reply.started":"2023-12-10T16:07:08.886199Z","shell.execute_reply":"2023-12-10T16:09:47.925689Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Saved: english.pkl\nresumption of the session\ni declare resumed the session of the european parliament adjourned on friday december and i would like once again to wish you a happy new year in the hope that you enjoyed a pleasant festive period\nalthough as you will have seen the dreaded millennium bug failed to materialise still the people in a number of countries suffered a series of natural disasters that truly were dreadful\nyou have requested a debate on this subject in the course of the next few days during this partsession\nin the meantime i should like to observe a minute s silence as a number of members have requested on behalf of all the victims concerned particularly those of the terrible storms in the various countries of the european union\nplease rise then for this minute s silence\nthe house rose and observed a minute s silence\nmadam president on a point of order\nyou will be aware from the press and television that there have been a number of bomb explosions and killings in sri lanka\none of the people assassinated very recently in sri lanka was mr kumar ponnambalam who had visited the european parliament just a few months ago\nSaved: french.pkl\nreprise de la session\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2007718  i would also like although they are absent to ...   \n2007719  i am not going to reopen the millennium or not...   \n2007720                         adjournment of the session   \n2007721  i declare the session of the european parliame...   \n2007722                       the sitting was closed at am   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2007718  je me permettrai meme bien quils soient absent...  \n2007719  je ne rouvrirai pas le debat sur le millenaire...  \n2007720                         interruption de la session  \n2007721  je declare interrompue la session du parlement...  \n2007722                              la seance est levee a  \n\n[2007723 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2007718</th>\n      <td>i would also like although they are absent to ...</td>\n      <td>je me permettrai meme bien quils soient absent...</td>\n    </tr>\n    <tr>\n      <th>2007719</th>\n      <td>i am not going to reopen the millennium or not...</td>\n      <td>je ne rouvrirai pas le debat sur le millenaire...</td>\n    </tr>\n    <tr>\n      <th>2007720</th>\n      <td>adjournment of the session</td>\n      <td>interruption de la session</td>\n    </tr>\n    <tr>\n      <th>2007721</th>\n      <td>i declare the session of the european parliame...</td>\n      <td>je declare interrompue la session du parlement...</td>\n    </tr>\n    <tr>\n      <th>2007722</th>\n      <td>the sitting was closed at am</td>\n      <td>la seance est levee a</td>\n    </tr>\n  </tbody>\n</table>\n<p>2007723 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data2 = pd.read_csv('./data/eng-fra.txt', delimiter='\\t', names = ['English', 'French'])\ndata2","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:09:47.928272Z","iopub.execute_input":"2023-12-10T16:09:47.928763Z","iopub.status.idle":"2023-12-10T16:09:48.178586Z","shell.execute_reply.started":"2023-12-10T16:09:47.928735Z","shell.execute_reply":"2023-12-10T16:09:48.177627Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                                  English  \\\n0                                                     Go.   \n1                                                    Run!   \n2                                                    Run!   \n3                                                    Wow!   \n4                                                   Fire!   \n...                                                   ...   \n135837  A carbon footprint is the amount of carbon dio...   \n135838  Death is something that we're often discourage...   \n135839  Since there are usually multiple websites on a...   \n135840  If someone who doesn't know your background sa...   \n135841  It may be impossible to get a completely error...   \n\n                                                   French  \n0                                                    Va !  \n1                                                 Cours !  \n2                                                Courez !  \n3                                              Ça alors !  \n4                                                Au feu !  \n...                                                   ...  \n135837  Une empreinte carbone est la somme de pollutio...  \n135838  La mort est une chose qu'on nous décourage sou...  \n135839  Puisqu'il y a de multiples sites web sur chaqu...  \n135840  Si quelqu'un qui ne connaît pas vos antécédent...  \n135841  Il est peut-être impossible d'obtenir un Corpu...  \n\n[135842 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Go.</td>\n      <td>Va !</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Run!</td>\n      <td>Cours !</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Run!</td>\n      <td>Courez !</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wow!</td>\n      <td>Ça alors !</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Fire!</td>\n      <td>Au feu !</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>135837</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>135838</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>135839</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>135840</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>135841</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>135842 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data = pd.concat([data,data2], ignore_index= True, axis = 0)\n\ndata.to_csv('eng-fra.txt')\ndata","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:09:48.180182Z","iopub.execute_input":"2023-12-10T16:09:48.180524Z","iopub.status.idle":"2023-12-10T16:10:20.279284Z","shell.execute_reply.started":"2023-12-10T16:09:48.180496Z","shell.execute_reply":"2023-12-10T16:10:20.278271Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                                   English  \\\n0                                resumption of the session   \n1        i declare resumed the session of the european ...   \n2        although as you will have seen the dreaded mil...   \n3        you have requested a debate on this subject in...   \n4        in the meantime i should like to observe a min...   \n...                                                    ...   \n2143560  A carbon footprint is the amount of carbon dio...   \n2143561  Death is something that we're often discourage...   \n2143562  Since there are usually multiple websites on a...   \n2143563  If someone who doesn't know your background sa...   \n2143564  It may be impossible to get a completely error...   \n\n                                                    French  \n0                                    reprise de la session  \n1        je declare reprise la session du parlement eur...  \n2        comme vous avez pu le constater le grand bogue...  \n3        vous avez souhaite un debat a ce sujet dans le...  \n4        en attendant je souhaiterais comme un certain ...  \n...                                                    ...  \n2143560  Une empreinte carbone est la somme de pollutio...  \n2143561  La mort est une chose qu'on nous décourage sou...  \n2143562  Puisqu'il y a de multiples sites web sur chaqu...  \n2143563  Si quelqu'un qui ne connaît pas vos antécédent...  \n2143564  Il est peut-être impossible d'obtenir un Corpu...  \n\n[2143565 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>English</th>\n      <th>French</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>resumption of the session</td>\n      <td>reprise de la session</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>i declare resumed the session of the european ...</td>\n      <td>je declare reprise la session du parlement eur...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>although as you will have seen the dreaded mil...</td>\n      <td>comme vous avez pu le constater le grand bogue...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>you have requested a debate on this subject in...</td>\n      <td>vous avez souhaite un debat a ce sujet dans le...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>in the meantime i should like to observe a min...</td>\n      <td>en attendant je souhaiterais comme un certain ...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2143560</th>\n      <td>A carbon footprint is the amount of carbon dio...</td>\n      <td>Une empreinte carbone est la somme de pollutio...</td>\n    </tr>\n    <tr>\n      <th>2143561</th>\n      <td>Death is something that we're often discourage...</td>\n      <td>La mort est une chose qu'on nous décourage sou...</td>\n    </tr>\n    <tr>\n      <th>2143562</th>\n      <td>Since there are usually multiple websites on a...</td>\n      <td>Puisqu'il y a de multiples sites web sur chaqu...</td>\n    </tr>\n    <tr>\n      <th>2143563</th>\n      <td>If someone who doesn't know your background sa...</td>\n      <td>Si quelqu'un qui ne connaît pas vos antécédent...</td>\n    </tr>\n    <tr>\n      <th>2143564</th>\n      <td>It may be impossible to get a completely error...</td>\n      <td>Il est peut-être impossible d'obtenir un Corpu...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2143565 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\nimport torchtext\nfrom torchtext.data import get_tokenizer\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:20.280595Z","iopub.execute_input":"2023-12-10T16:10:20.280930Z","iopub.status.idle":"2023-12-10T16:10:21.632949Z","shell.execute_reply.started":"2023-12-10T16:10:20.280903Z","shell.execute_reply":"2023-12-10T16:10:21.632118Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1\n\nclass Voc:\n    def __init__(self, name):\n        self.name = name\n        self.w2i = {}\n        self.w2c = {}\n        self.i2w = {0: \"SOS\", 1: \"EOS\"}\n        self.num_of_W = 2 \n\n    def insertSeq(self, seq):\n        for word in seq.split(' '):\n            self.insertWord(word)\n\n    def insertWord(self, word):\n        if word not in self.w2i:\n            self.w2i[word] = self.num_of_W\n            self.w2c[word] = 1\n            self.i2w[self.num_of_W] = word\n            self.num_of_W += 1\n        else:\n            self.w2c[word] += 1","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:21.634150Z","iopub.execute_input":"2023-12-10T16:10:21.634734Z","iopub.status.idle":"2023-12-10T16:10:21.642259Z","shell.execute_reply.started":"2023-12-10T16:10:21.634687Z","shell.execute_reply":"2023-12-10T16:10:21.641257Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def removeNonLettersAndLowercase(s):\n    s = ''.join(c for c in unicodedata.normalize('NFD', s.lower().strip()) if unicodedata.category(c) != 'Mn')\n    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n    return s.strip()","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:21.643793Z","iopub.execute_input":"2023-12-10T16:10:21.644657Z","iopub.status.idle":"2023-12-10T16:10:21.657696Z","shell.execute_reply.started":"2023-12-10T16:10:21.644619Z","shell.execute_reply":"2023-12-10T16:10:21.656815Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def rVocs(Voc1, Voc2, reverse=False):\n    print(\"Reading lines...\")\n\n    lines = open('data/%s-%s.txt' % (Voc1, Voc2), encoding='utf-8').read().strip().split('\\n')\n    pairs = [[removeNonLettersAndLowercase(s) for s in l.split('\\t')] for l in lines]\n    if reverse:\n        pairs = [list(reversed(p)) for p in pairs]\n        i_Voc = Voc(Voc2)\n        o_Voc = Voc(Voc1)\n    else:\n        i_Voc = Voc(Voc1)\n        o_Voc = Voc(Voc2)\n\n    return i_Voc, o_Voc, pairs","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:21.659044Z","iopub.execute_input":"2023-12-10T16:10:21.659428Z","iopub.status.idle":"2023-12-10T16:10:21.668007Z","shell.execute_reply.started":"2023-12-10T16:10:21.659389Z","shell.execute_reply":"2023-12-10T16:10:21.667109Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def processData(Voc1, Voc2, reverse=False):\n    i_Voc, o_Voc, pairs = rVocs(Voc1, Voc2, reverse)\n    print(\"Read %s sentence pairs\" % len(pairs))\n    pairs = [p for p in pairs if len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH]\n    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n    print(\"Counting words...\")\n    for pair in pairs:\n        i_Voc.insertSeq(pair[0])\n        o_Voc.insertSeq(pair[1])\n    print(i_Voc.name, i_Voc.num_of_W)\n    print(o_Voc.name, o_Voc.num_of_W)\n    return i_Voc, o_Voc, pairs\n\ni_Voc, o_Voc, pairs = processData('eng', 'fra', True)\nprint(random.choice(pairs))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:21.687841Z","iopub.execute_input":"2023-12-10T16:10:21.688573Z","iopub.status.idle":"2023-12-10T16:10:29.790253Z","shell.execute_reply.started":"2023-12-10T16:10:21.688545Z","shell.execute_reply":"2023-12-10T16:10:29.789208Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 122295 sentence pairs\nCounting words...\nCounted words:\nfra 19507\neng 11759\n['presque un millier de personnes ont pris part a la manifestation', 'nearly a thousand people participated in the demonstration']\n","output_type":"stream"}]},{"cell_type":"code","source":"MAX_LENGTH = 20","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, i_s, h_s, dropout_p=0.1):\n        super(Encoder, self).__init__()\n        self.h_s = h_s\n        self.embedding = nn.Embedding(i_s, h_s)\n        self.gru = nn.GRU(h_s, h_s, batch_first=True)\n        self.dropout = nn.Dropout(dropout_p)\n\n    def forward(self, input):\n        embedded = self.dropout(self.embedding(input))\n        o, hidden = self.gru(embedded)\n        return o, hidden","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:29.791327Z","iopub.execute_input":"2023-12-10T16:10:29.791611Z","iopub.status.idle":"2023-12-10T16:10:29.798379Z","shell.execute_reply.started":"2023-12-10T16:10:29.791588Z","shell.execute_reply":"2023-12-10T16:10:29.797349Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, h_s, o_s):\n        super(Decoder, self).__init__()\n        self.embedding = nn.Embedding(o_s, h_s)\n        self.gru = nn.GRU(h_s, h_s, batch_first=True)\n        self.out = nn.Linear(h_s, o_s)\n\n    def forward(self, e_o, e_h, t_t=None):\n        batch_size = e_o.size(0)\n        d_i = torch.empty(batch_size, 1, dtype=torch.long, device=device).fill_(SOS_token)\n        d_h = e_h\n        d_os = []\n\n        for i in range(MAX_LENGTH):\n            d_o, d_h  = self.forward(d_i, d_h)\n            d_os.append(d_o)\n\n            if t_t is not None:\n                d_i = t_t[:, i].unsqueeze(1)\n            else:\n                _, topi = d_o.topk(1)\n                d_i = topi.squeeze(-1).detach()  \n\n        d_os = torch.cat(d_os, dim=1)\n        d_os = F.log_softmax(d_os, dim=-1)\n        return d_os, d_h, None\n\n    def forward(self, input, hidden):\n        o = self.embedding(input)\n        o = F.relu(o)\n        o, hidden = self.gru(o, hidden)\n        o = self.out(o)\n        return o, hidden","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:29.799831Z","iopub.execute_input":"2023-12-10T16:10:29.800247Z","iopub.status.idle":"2023-12-10T16:10:29.816497Z","shell.execute_reply.started":"2023-12-10T16:10:29.800212Z","shell.execute_reply":"2023-12-10T16:10:29.815506Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ndef i_f_s(Voc, sentence):\n    return [Voc.w2i[word] for word in sentence.split(' ')]\n\ndef t_f_s(Voc, sentence):\n    indexes = i_f_s(Voc, sentence)\n    indexes.append(EOS_token)\n    return torch.tensor(indexes, dtype=torch.long, device=device).view(1, -1)\n\ndef t_f_p(pair):\n    i_t = t_f_s(i_Voc, pair[0])\n    t_t = t_f_s(o_Voc, pair[1])\n    return (i_t, t_t)\n\ndef get_data(batch_size):\n    i_Voc, o_Voc, pairs = processData('eng', 'fra', True)\n\n    n = len(pairs)\n    input_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n    target_ids = np.zeros((n, MAX_LENGTH), dtype=np.int32)\n\n    for idx, (inp, tgt) in enumerate(pairs):\n        inp_ids = i_f_s(i_Voc, inp)\n        tgt_ids = i_f_s(o_Voc, tgt)\n        inp_ids.append(EOS_token)\n        tgt_ids.append(EOS_token)\n        input_ids[idx, :len(inp_ids)] = inp_ids\n        target_ids[idx, :len(tgt_ids)] = tgt_ids\n\n    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n                               torch.LongTensor(target_ids).to(device))\n    \n    train_pairs, test_pairs = train_test_split(train_data, test_size=0.3, random_state=42)\n    val_pairs, test_pairs = train_test_split(test_pairs, test_size=0.5, random_state=42)\n    print('len of training samples ', len(train_pairs))\n\n    \n    train_dataloader = DataLoader(train_pairs, batch_size=batch_size, shuffle= True)\n    test_dataloader = DataLoader(test_pairs, batch_size=batch_size, shuffle= True)\n    val_dataloader = DataLoader(val_pairs, batch_size=batch_size, shuffle= True)                                        \n    return i_Voc, o_Voc, train_dataloader, test_dataloader, val_dataloader","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:29.817852Z","iopub.execute_input":"2023-12-10T16:10:29.818807Z","iopub.status.idle":"2023-12-10T16:10:30.315910Z","shell.execute_reply.started":"2023-12-10T16:10:29.818766Z","shell.execute_reply":"2023-12-10T16:10:30.314908Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.317168Z","iopub.execute_input":"2023-12-10T16:10:30.317520Z","iopub.status.idle":"2023-12-10T16:10:30.323519Z","shell.execute_reply.started":"2023-12-10T16:10:30.317487Z","shell.execute_reply":"2023-12-10T16:10:30.322572Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    for data in dataloader:\n        i_t, t_t = data\n\n        encoder_optimizer.zero_grad()\n        decoder_optimizer.zero_grad()\n\n        e_o, e_h = encoder(i_t)\n        d_os, _, _ = decoder(e_o, e_h, t_t)\n        \n        _, predicted = d_os.max(dim=2)\n        correct = (predicted == t_t)\n        accuracy = correct.sum().item() / (t_t.size(0) * t_t.size(1))\n\n        loss = criterion(\n            d_os.view(-1, d_os.size(-1)),\n            t_t.view(-1)\n        )\n        loss.backward()\n\n        encoder_optimizer.step()\n        decoder_optimizer.step()\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader), accuracy","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.324774Z","iopub.execute_input":"2023-12-10T16:10:30.325060Z","iopub.status.idle":"2023-12-10T16:10:30.338446Z","shell.execute_reply.started":"2023-12-10T16:10:30.325023Z","shell.execute_reply":"2023-12-10T16:10:30.337482Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"def evaluate_epoch(dataloader, encoder, decoder, encoder_optimizer,\n          decoder_optimizer, criterion):\n\n    total_loss = 0\n    #encoder.eval()\n    #decoder.eval()\n    for data in dataloader:\n        i_t, t_t = data\n\n        \n        e_o, e_h = encoder(i_t)\n        d_os, _, _ = decoder(e_o, e_h, t_t)\n\n        loss = criterion(\n            d_os.view(-1, d_os.size(-1)),\n            t_t.view(-1)\n        )\n\n\n        total_loss += loss.item()\n\n    return total_loss / len(dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.339770Z","iopub.execute_input":"2023-12-10T16:10:30.340151Z","iopub.status.idle":"2023-12-10T16:10:30.348885Z","shell.execute_reply.started":"2023-12-10T16:10:30.340125Z","shell.execute_reply":"2023-12-10T16:10:30.348048Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.350180Z","iopub.execute_input":"2023-12-10T16:10:30.351235Z","iopub.status.idle":"2023-12-10T16:10:30.360241Z","shell.execute_reply.started":"2023-12-10T16:10:30.351207Z","shell.execute_reply":"2023-12-10T16:10:30.359318Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.361288Z","iopub.execute_input":"2023-12-10T16:10:30.361551Z","iopub.status.idle":"2023-12-10T16:10:30.375227Z","shell.execute_reply.started":"2023-12-10T16:10:30.361527Z","shell.execute_reply":"2023-12-10T16:10:30.374285Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def train(train_dataloader, val_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n               print_every=100, plot_every=100):\n    start = time.time()\n    plot_losses = []\n    plt_val_losses = []\n    accuracies = []\n    print_loss_total = 0 \n    plot_loss_total = 0 \n    plt_val_loss = 0\n    print_val_loss_total = 0\n\n    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n    criterion = nn.NLLLoss()\n\n    for epoch in range(1, n_epochs + 1):\n        loss, accuracy = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        val_loss = evaluate_epoch(val_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        print_val_loss_total += val_loss\n        plot_loss_total += loss\n\n        if epoch % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            val_loss_avg = print_val_loss_total / print_every\n            print_loss_total = 0\n            print_val_loss_total = 0\n            print('%s (%d %d %d%% ) %.4f' % (timeSince(start, epoch / n_epochs),\n                                        epoch, epoch / n_epochs * 100, print_loss_avg, val_loss_avg))\n            print('training_loss ', print_loss_avg, 'val_loss_avg ', val_loss_avg, ' accuracy ', accuracy)\n\n        if epoch % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plt_val_avg = print_val_loss_total / plot_every\n            plt_val_losses.append(plt_val_avg)\n            accuracies.append(accuracy)\n            plot_loss_total = 0\n            print_val_loss_total = 0\n\n    showPlot(plot_losses)\n    showPlot(plt_val_losses)\n    showPlot(accuracies)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.376463Z","iopub.execute_input":"2023-12-10T16:10:30.376778Z","iopub.status.idle":"2023-12-10T16:10:30.389034Z","shell.execute_reply.started":"2023-12-10T16:10:30.376751Z","shell.execute_reply":"2023-12-10T16:10:30.388040Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"def evaluate(encoder, decoder, input_tensor, input_lang, output_lang):\n    with torch.no_grad():\n        input_tensor = tensorFromSentence(input_lang, input_tensor)\n\n        encoder_outputs, encoder_hidden = encoder(input_tensor)\n        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n\n        _, topi = decoder_outputs.topk(1)\n        decoded_ids = topi.squeeze()\n\n        decoded_words = []\n        for idx in decoded_ids:\n            if idx.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            decoded_words.append(output_lang.index2word[idx.item()])\n    return decoded_words, decoder_attn","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.390024Z","iopub.execute_input":"2023-12-10T16:10:30.390284Z","iopub.status.idle":"2023-12-10T16:10:30.404594Z","shell.execute_reply.started":"2023-12-10T16:10:30.390261Z","shell.execute_reply":"2023-12-10T16:10:30.403714Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, _ = evaluate(encoder, decoder, pair[0], input_lang, output_lang)\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.405768Z","iopub.execute_input":"2023-12-10T16:10:30.406092Z","iopub.status.idle":"2023-12-10T16:10:30.419359Z","shell.execute_reply.started":"2023-12-10T16:10:30.406065Z","shell.execute_reply":"2023-12-10T16:10:30.418567Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\n\n\ninput_lang, output_lang, train_dataloader, test_pairs, val_dataloader = get_dataloader(batch_size)\ntest_dataloader = DataLoader(test_pairs, batch_size=batch_size, shuffle= True)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:30.420615Z","iopub.execute_input":"2023-12-10T16:10:30.420961Z","iopub.status.idle":"2023-12-10T16:10:43.882180Z","shell.execute_reply.started":"2023-12-10T16:10:30.420926Z","shell.execute_reply":"2023-12-10T16:10:43.881073Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 122295 sentence pairs\nCounting words...\nCounted words:\nfra 19507\neng 11759\nlen of training samples  85606\n","output_type":"stream"}]},{"cell_type":"code","source":"hidden_size = 128\nbatch_size = 32\n\n\n\ninput_lang, output_lang, train_dataloader, test_dataloader, val_dataloader = get_dataloader(batch_size)\n\nencoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\ndecoder = DecoderRNN(hidden_size, output_lang.n_words).to(device)\n\ntrain(train_dataloader, val_dataloader, encoder, decoder, 55, print_every=1, plot_every=5)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:10:43.883504Z","iopub.execute_input":"2023-12-10T16:10:43.883835Z","iopub.status.idle":"2023-12-10T16:42:08.041930Z","shell.execute_reply.started":"2023-12-10T16:10:43.883807Z","shell.execute_reply":"2023-12-10T16:42:08.040413Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Reading lines...\nRead 135842 sentence pairs\nTrimmed to 122295 sentence pairs\nCounting words...\nCounted words:\nfra 19507\neng 11759\nlen of training samples  85606\n0m 34s (- 31m 29s) (1 1 2% ) 1.9629\ntraining_loss  2.4682893043409013 val_loss_avg  1.9629274361640319  accuracy  0.7361111111111112\n1m 9s (- 30m 42s) (2 3 1% ) 1.6644\ntraining_loss  1.7613649538903315 val_loss_avg  1.6644275373282749  accuracy  0.7777777777777778\n1m 43s (- 30m 1s) (3 5 1% ) 1.5096\ntraining_loss  1.4906892455078562 val_loss_avg  1.5096381391797746  accuracy  0.7638888888888888\n2m 18s (- 29m 21s) (4 7 1% ) 1.3998\ntraining_loss  1.3060284457399172 val_loss_avg  1.3998025767894573  accuracy  0.7638888888888888\n2m 52s (- 28m 41s) (5 9 1% ) 1.3287\ntraining_loss  1.1647089270510125 val_loss_avg  1.328714323895318  accuracy  0.6527777777777778\n3m 26s (- 28m 5s) (6 10 1% ) 1.2715\ntraining_loss  1.0510568253261625 val_loss_avg  1.2715442018641827  accuracy  0.875\n4m 0s (- 27m 30s) (7 12 0% ) 1.2334\ntraining_loss  0.9575106290423817 val_loss_avg  1.233407763861613  accuracy  0.8472222222222222\n4m 34s (- 26m 54s) (8 14 0% ) 1.2028\ntraining_loss  0.8805099277574742 val_loss_avg  1.2028494779968095  accuracy  0.8472222222222222\n5m 9s (- 26m 19s) (9 16 0% ) 1.1812\ntraining_loss  0.8148089583367332 val_loss_avg  1.181187423264108  accuracy  0.75\n5m 43s (- 25m 44s) (10 18 0% ) 1.1646\ntraining_loss  0.7588603712384476 val_loss_avg  1.1645654056753432  accuracy  0.8194444444444444\n6m 17s (- 25m 9s) (11 20 0% ) 1.1521\ntraining_loss  0.7102505750230254 val_loss_avg  1.1520928927414924  accuracy  0.7777777777777778\n6m 52s (- 24m 37s) (12 21 0% ) 1.1374\ntraining_loss  0.6679171083330752 val_loss_avg  1.1374001285963358  accuracy  0.9305555555555556\n7m 27s (- 24m 4s) (13 23 0% ) 1.1308\ntraining_loss  0.6304305184448781 val_loss_avg  1.1307679241334936  accuracy  0.8888888888888888\n8m 2s (- 23m 32s) (14 25 0% ) 1.1255\ntraining_loss  0.5967635699897247 val_loss_avg  1.1255085067466577  accuracy  0.8194444444444444\n8m 37s (- 22m 58s) (15 27 0% ) 1.1241\ntraining_loss  0.5673689958047795 val_loss_avg  1.1240544230888114  accuracy  0.8194444444444444\n9m 11s (- 22m 23s) (16 29 0% ) 1.1198\ntraining_loss  0.54025792357232 val_loss_avg  1.1197819349450102  accuracy  0.8611111111111112\n9m 45s (- 21m 48s) (17 30 0% ) 1.1246\ntraining_loss  0.5159529596789891 val_loss_avg  1.1245974203643068  accuracy  0.875\n10m 19s (- 21m 13s) (18 32 0% ) 1.1221\ntraining_loss  0.494185462677559 val_loss_avg  1.1220670435902134  accuracy  0.9166666666666666\n10m 53s (- 20m 38s) (19 34 0% ) 1.1254\ntraining_loss  0.473763518274855 val_loss_avg  1.1253985685753904  accuracy  0.9166666666666666\n11m 27s (- 20m 3s) (20 36 0% ) 1.1298\ntraining_loss  0.45511363930610443 val_loss_avg  1.1298058257285726  accuracy  0.9444444444444444\n12m 1s (- 19m 28s) (21 38 0% ) 1.1336\ntraining_loss  0.4381974531039707 val_loss_avg  1.1336119534246598  accuracy  0.9027777777777778\n12m 36s (- 18m 54s) (22 40 0% ) 1.1343\ntraining_loss  0.4223266824667853 val_loss_avg  1.1342766821799792  accuracy  0.875\n13m 10s (- 18m 19s) (23 41 0% ) 1.1375\ntraining_loss  0.4074104511539587 val_loss_avg  1.1375017968308219  accuracy  0.9305555555555556\n13m 44s (- 17m 45s) (24 43 0% ) 1.1437\ntraining_loss  0.39403000114811376 val_loss_avg  1.1436978396846027  accuracy  0.8611111111111112\n14m 18s (- 17m 10s) (25 45 0% ) 1.1515\ntraining_loss  0.38131174134433005 val_loss_avg  1.151483532755217  accuracy  0.9305555555555556\n14m 52s (- 16m 36s) (26 47 0% ) 1.1494\ntraining_loss  0.36947733971258273 val_loss_avg  1.1493945054787793  accuracy  0.8888888888888888\n15m 27s (- 16m 1s) (27 49 0% ) 1.1549\ntraining_loss  0.3589576882754295 val_loss_avg  1.1549232457780672  accuracy  0.9305555555555556\n16m 1s (- 15m 27s) (28 50 0% ) 1.1610\ntraining_loss  0.34815208804870224 val_loss_avg  1.1610182331621854  accuracy  0.9444444444444444\n16m 35s (- 14m 52s) (29 52 0% ) 1.1702\ntraining_loss  0.33815367895725595 val_loss_avg  1.1702305450256694  accuracy  0.8333333333333334\n17m 9s (- 14m 18s) (30 54 0% ) 1.1770\ntraining_loss  0.32932124323084927 val_loss_avg  1.1769802979475945  accuracy  0.8194444444444444\n17m 43s (- 13m 43s) (31 56 0% ) 1.1812\ntraining_loss  0.3208912923174767 val_loss_avg  1.181196109758437  accuracy  0.875\n18m 18s (- 13m 9s) (32 58 0% ) 1.1911\ntraining_loss  0.3119839035108218 val_loss_avg  1.1910828104833278  accuracy  0.9444444444444444\n18m 52s (- 12m 34s) (33 60 0% ) 1.1927\ntraining_loss  0.3048703086316051 val_loss_avg  1.1926830403688478  accuracy  0.9305555555555556\n19m 26s (- 12m 0s) (34 61 0% ) 1.2013\ntraining_loss  0.2972621350355658 val_loss_avg  1.201324210453532  accuracy  0.9166666666666666\n20m 0s (- 11m 25s) (35 63 0% ) 1.2084\ntraining_loss  0.2905369412476929 val_loss_avg  1.2083977620776107  accuracy  0.9444444444444444\n20m 34s (- 10m 51s) (36 65 0% ) 1.2150\ntraining_loss  0.28440313494203245 val_loss_avg  1.2150483519254245  accuracy  0.8472222222222222\n21m 8s (- 10m 17s) (37 67 0% ) 1.2205\ntraining_loss  0.2770999038121447 val_loss_avg  1.2205430659682908  accuracy  0.8888888888888888\n21m 43s (- 9m 42s) (38 69 0% ) 1.2256\ntraining_loss  0.27156069638939806 val_loss_avg  1.2255581016116857  accuracy  0.9305555555555556\n22m 17s (- 9m 8s) (39 70 0% ) 1.2366\ntraining_loss  0.26631985021468324 val_loss_avg  1.236608084953205  accuracy  0.9166666666666666\n22m 51s (- 8m 34s) (40 72 0% ) 1.2360\ntraining_loss  0.260832650915501 val_loss_avg  1.2360036589127383  accuracy  0.9305555555555556\n23m 25s (- 7m 59s) (41 74 0% ) 1.2473\ntraining_loss  0.2559547391573944 val_loss_avg  1.2473267351085715  accuracy  0.9722222222222222\n23m 59s (- 7m 25s) (42 76 0% ) 1.2483\ntraining_loss  0.25032331088699833 val_loss_avg  1.2482767402087354  accuracy  0.8611111111111112\n24m 33s (- 6m 51s) (43 78 0% ) 1.2574\ntraining_loss  0.24493917360935244 val_loss_avg  1.2573626989479265  accuracy  0.875\n25m 6s (- 6m 16s) (44 80 0% ) 1.2605\ntraining_loss  0.2411074059638118 val_loss_avg  1.2604753490835947  accuracy  0.8888888888888888\n25m 39s (- 5m 42s) (45 81 0% ) 1.2707\ntraining_loss  0.2370750280974157 val_loss_avg  1.2706892985707792  accuracy  0.9444444444444444\n26m 12s (- 5m 7s) (46 83 0% ) 1.2828\ntraining_loss  0.23286247620656975 val_loss_avg  1.2828021828305847  accuracy  0.875\n26m 45s (- 4m 33s) (47 85 0% ) 1.2841\ntraining_loss  0.22902245662816884 val_loss_avg  1.2840771146559964  accuracy  0.9305555555555556\n27m 18s (- 3m 58s) (48 87 0% ) 1.2957\ntraining_loss  0.2251633135810695 val_loss_avg  1.2957074211241892  accuracy  0.9305555555555556\n27m 51s (- 3m 24s) (49 89 0% ) 1.2921\ntraining_loss  0.22134338464638043 val_loss_avg  1.292089030406201  accuracy  0.9583333333333334\n28m 24s (- 2m 50s) (50 90 0% ) 1.3040\ntraining_loss  0.21798397622646148 val_loss_avg  1.3039746679080073  accuracy  0.9861111111111112\n28m 57s (- 2m 16s) (51 92 0% ) 1.3134\ntraining_loss  0.21469788297576486 val_loss_avg  1.3133882555189034  accuracy  0.9722222222222222\n29m 30s (- 1m 42s) (52 94 0% ) 1.3190\ntraining_loss  0.21055650773426166 val_loss_avg  1.3189981753194788  accuracy  0.9583333333333334\n30m 3s (- 1m 8s) (53 96 0% ) 1.3229\ntraining_loss  0.2082172801331109 val_loss_avg  1.3228743603316748  accuracy  0.9444444444444444\n30m 36s (- 0m 34s) (54 98 0% ) 1.3215\ntraining_loss  0.20478996292023915 val_loss_avg  1.321525114286652  accuracy  0.9722222222222222\n31m 11s (- 0m 0s) (55 100 0% ) 1.3369\ntraining_loss  0.20182843090094882 val_loss_avg  1.3369307975943496  accuracy  0.9861111111111112\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\nevaluateRandomly(encoder, decoder)","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:42:08.044312Z","iopub.execute_input":"2023-12-10T16:42:08.044827Z","iopub.status.idle":"2023-12-10T16:42:08.135653Z","shell.execute_reply.started":"2023-12-10T16:42:08.044780Z","shell.execute_reply":"2023-12-10T16:42:08.134690Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"> j etais l homme le plus heureux de la terre\n= i was the happiest man on earth\n< i was the happiest man on earth <EOS>\n\n> je vais te montrer la ville\n= i will show you around the city\n< i ll show you the town <EOS>\n\n> ils ont redige un projet de loi sur la sante\n= they ve written a bill for health care\n< they ve written a foreign trade every day <EOS>\n\n> je suis tres strict\n= i m very strict\n< i m very strict <EOS>\n\n> cette viande s est gatee\n= this meat has gone bad\n< this thing is terrible at all different <EOS>\n\n> je vais le mettre dans ma chambre\n= i m going to put it in my room\n< i ll put my room back <EOS>\n\n> on a donne une medaille a tom\n= tom was given a medal\n< tom was given a medal <EOS>\n\n> il n est pas poli de montrer les autres du doigt\n= it is not polite to point at others\n< it is no easy to keep from his attention <EOS>\n\n> je viens d angleterre\n= i come from england\n< i just changed <EOS>\n\n> je pense que nous ferions mieux d aider tom\n= i think we d better help tom\n< i think maybe tom d do not appreciate <EOS>\n\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(encoder.state_dict(), 'encoder_weights.pth')\n","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:42:08.136807Z","iopub.execute_input":"2023-12-10T16:42:08.137091Z","iopub.status.idle":"2023-12-10T16:42:08.164962Z","shell.execute_reply.started":"2023-12-10T16:42:08.137067Z","shell.execute_reply":"2023-12-10T16:42:08.164024Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"torch.save(decoder.state_dict(), 'decoder_weights.pth')","metadata":{"execution":{"iopub.status.busy":"2023-12-10T16:42:08.166065Z","iopub.execute_input":"2023-12-10T16:42:08.166400Z","iopub.status.idle":"2023-12-10T16:42:08.191388Z","shell.execute_reply.started":"2023-12-10T16:42:08.166373Z","shell.execute_reply":"2023-12-10T16:42:08.190495Z"},"trusted":true},"execution_count":30,"outputs":[]}]}